{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from functions.models import \n",
    "from functions.datasets import getDatasets\n",
    "from functions.metrics import evaluator\n",
    "from functions.plot import ROC, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = 'baseline1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1000.0,\n",
       " 'clf__penalty': 'l2',\n",
       " 'vect__max_df': 1,\n",
       " 'vect__max_features': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'pan13_en'\n",
    "task = 'age'\n",
    "\n",
    "def getBestParams(task, dataset_name):\n",
    "    \n",
    "    dataset_name = dataset_name.strip().lower()\n",
    "    task = task.strip().lower()\n",
    "    \n",
    "    # load excel params\n",
    "    baseline1 = pd.read_excel('./Reports/Reports.xlsx', baseline)\n",
    "    baseline1['Task'] = baseline1['Task'].str.lower()\n",
    "    baseline1['Name'] = baseline1['Name'].str.lower()\n",
    "    \n",
    "    best_params = baseline1[(baseline1['Name'] == dataset_name) & (baseline1['Task'] == task)]\n",
    "    \n",
    "    max_features = best_params['max features'].values[0]\n",
    "    \n",
    "    model_params = {\n",
    "                    'vect__max_features': max_features if max_features != 'None' and not pd.isna(max_features) else None,\n",
    "                    'vect__max_df': best_params['max df'].values[0] if not pd.isna(best_params['max df'].values[0]) else 1,\n",
    "                    'clf__C': best_params['C'].values[0] if not pd.isna(best_params['C'].values[0]) else 1000.0, \n",
    "                    'clf__penalty': best_params['P'].values[0] if not pd.isna(best_params['P'].values[0]) else 'l2'\n",
    "                    }\n",
    "    \n",
    "    return model_params\n",
    "\n",
    "getBestParams(task, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoder(y):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y)\n",
    "\n",
    "    return (le.transform(y), len(le.classes_), list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    space = ' '    \n",
    "    for char in ['\\n','-', '...', '*', '/', '+', '\\\\']:\n",
    "        text = text.replace(char, space)\n",
    "        \n",
    "    text = text.replace(space*2, space)\n",
    "    text = text.replace(space*3, space)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform classification for each problem / task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, y, n_classes, classes_name, params):\n",
    "                \n",
    "    pipeline = Pipeline([       \n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),        \n",
    "        ('clf', LogisticRegression(verbose=1)),\n",
    "    ])\n",
    "    \n",
    "    # pipeline.set_params(**params)    \n",
    "    vect = TfidfVectorizer(max_features=params.get('vect__max_features'), max_df=params.get('vect__max_df'))\n",
    "    \n",
    "    K = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    t0 = time()\n",
    "    \n",
    "    predicted_y = []\n",
    "    expected_y = []    \n",
    "    score_y = []\n",
    "    \n",
    "    for train_index, test_index in K.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        X_train = vect.fit_transform(X_train)\n",
    "        X_test = vect.transform(X_test)\n",
    "        \n",
    "        clf = LogisticRegression(C=params.get('clf__C'), penalty=params.get('clf__penalty'), solver='liblinear')\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        predicted_y.extend(clf.predict(X_test))\n",
    "        expected_y.extend(y_test)\n",
    "        score_y.extend(clf.predict_proba(X_test))\n",
    "\n",
    "        ### get train score\n",
    "\n",
    "    # print(\"done in %0.2fs and %0.1fmin\" % ((time() - t0), ((time() - t0) / 60) ))\n",
    "    # print()\n",
    "    \n",
    "    report = pd.DataFrame(classification_report(expected_y, predicted_y, digits=5, target_names=classes_name, output_dict=True))\n",
    "    report = report.transpose()\n",
    "    \n",
    "    return (\n",
    "        report, \n",
    "        np.asarray(expected_y),\n",
    "        np.asarray(predicted_y),\n",
    "        np.asarray(score_y)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(task, dataset_name, output = None):    \n",
    "    datasets = getDatasets(task,'df', dataset_name)\n",
    "    for i in datasets.iterrows():\n",
    "\n",
    "        name = i[1]['dataset_name']\n",
    "        label = task\n",
    "        ds_path = i[1]['path']\n",
    "\n",
    "        # load training and test dataframes\n",
    "        training_path = ds_path + '/' + i[1]['training']        \n",
    "\n",
    "        df_training = pd.read_csv(training_path)#, usecols=cols)        \n",
    "\n",
    "        df_training['text'] = df_training['text'].apply(clean)\n",
    "        X_train = df_training['text'].values\n",
    "        y_train, n_classes, classes_name = labelEncoder(df_training[label].values)\n",
    "\n",
    "        # del(df_training)\n",
    "\n",
    "        # print(\"Dataset: {0} and task: {1}\".format(name, label))\n",
    "\n",
    "        # print(\"n_classes: {0}\".format(n_classes))\n",
    "\n",
    "        params = getBestParams(task, dataset_name)\n",
    "        # print(\"params: \", params)\n",
    "\n",
    "        report, expected_y, predicted_y, score_y = model(X_train, y_train, n_classes, classes_name, params)\n",
    "\n",
    "        # get ROC\n",
    "        dataset_name = dataset_name + '/' + baseline\n",
    "        \n",
    "        roc_c = ROC(expected_y, score_y, n_classes, task, dataset_name, classes_name)\n",
    "        report['roc'] = list(roc_c.values()) + [roc_c['macro']] * 2\n",
    "\n",
    "        # compute accuracy\n",
    "        accuracy = accuracy_score(expected_y, predicted_y)\n",
    "        report['accuracy'] = [accuracy] * (n_classes + 3)\n",
    "\n",
    "        # compute confusion matrix\n",
    "        c_matrix = confusion_matrix(expected_y, predicted_y)\n",
    "        plot_confusion_matrix(c_matrix, classes_name, task, dataset_name, True)\n",
    "        cm = pd.DataFrame(c_matrix, columns=classes_name, index=classes_name)\n",
    "\n",
    "        directory = './Reports/' + task + '/' + dataset_name + '/'\n",
    "        report.to_csv(directory + 'report.csv')\n",
    "        cm.to_csv(directory + 'confusion_matrix.csv')    \n",
    "\n",
    "        print(report)\n",
    "\n",
    "        # output.put('results for {0} and {1}'.format(task, dataset_name))\n",
    "        # output.put(report.to_dict())\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import random\n",
    "import string\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "# Define an output queue\n",
    "output = mp.Queue()\n",
    "\n",
    "task_list = ['relig','polit','education','professional','region','TI']#,'gender','age']\n",
    "dataset_list = ['brmoral','b5post','esic','brblogset','enblogs','pan13_en','pan13_es','sms']\n",
    "\n",
    "args = []\n",
    "for task in task_list:\n",
    "    for ds in dataset_list:\n",
    "        d = getDatasets(task,'df', ds)\n",
    "        if len(d.values) > 0:\n",
    "            args.append([task, ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "              f1-score  precision    recall  support  roc  accuracy\n",
      "r12           0.705570   0.545082  1.000000    133.0  0.5  0.545082\n",
      "r3            0.000000   0.000000  0.000000     90.0  0.5  0.545082\n",
      "r45           0.000000   0.000000  0.000000     21.0  0.5  0.545082\n",
      "micro avg     0.545082   0.545082  0.545082    244.0  0.5  0.545082\n",
      "macro avg     0.235190   0.181694  0.333333    244.0  0.5  0.545082\n",
      "weighted avg  0.384594   0.297114  0.545082    244.0  0.5  0.545082\n",
      "Normalized confusion matrix\n",
      "[[0.48387097 0.26612903 0.25      ]\n",
      " [0.29807692 0.46153846 0.24038462]\n",
      " [0.3814433  0.34020619 0.27835052]]Normalized confusion matrix\n",
      "\n",
      "[[0.30841121 0.69158879]\n",
      " [0.1559633  0.8440367 ]]\n",
      "Normalized confusion matrix\n",
      "[[0.66071429 0.22321429 0.11607143]\n",
      " [0.24793388 0.54545455 0.20661157]\n",
      " [0.18478261 0.40217391 0.41304348]]\n",
      "                                     f1-score  precision    recall  support  \\\n",
      "Básico + Superior incompleto         0.476190   0.468750  0.483871    124.0   \n",
      "Pós-graduação andamento ou completo  0.440367   0.421053  0.461538    104.0   \n",
      "Superior completo                    0.300000   0.325301  0.278351     97.0   \n",
      "micro avg                            0.415385   0.415385  0.415385    325.0   \n",
      "macro avg                            0.405519   0.405035  0.407920    325.0   \n",
      "weighted avg                         0.412141   0.410673  0.415385    325.0   \n",
      "\n",
      "                                          roc  accuracy  \n",
      "Básico + Superior incompleto         0.609653  0.415385  \n",
      "Pós-graduação andamento ou completo  0.592238  0.415385  \n",
      "Superior completo                    0.508003  0.415385  \n",
      "micro avg                            0.572190  0.415385  \n",
      "macro avg                            0.572190  0.415385  \n",
      "weighted avg                         0.572190  0.415385                f1-score  precision    recall  support       roc  accuracy\n",
      "N             0.379310   0.492537  0.308411    107.0  0.339535  0.667692\n",
      "S             0.773109   0.713178  0.844037    218.0  0.660465  0.667692\n",
      "micro avg     0.667692   0.667692  0.667692    325.0  0.505252  0.667692\n",
      "macro avg     0.576210   0.602858  0.576224    325.0  0.505252  0.667692\n",
      "weighted avg  0.643459   0.640536  0.667692    325.0  0.505252  0.667692\n",
      "\n",
      "              f1-score  precision    recall  support       roc  accuracy\n",
      "p12           0.635193   0.611570  0.660714    112.0  0.772217  0.547692\n",
      "p3            0.530120   0.515625  0.545455    121.0  0.666099  0.547692\n",
      "p45           0.452381   0.500000  0.413043     92.0  0.687348  0.547692\n",
      "micro avg     0.547692   0.547692  0.547692    325.0  0.711101  0.547692\n",
      "macro avg     0.539232   0.542398  0.539737    325.0  0.711101  0.547692\n",
      "weighted avg  0.544324   0.544266  0.547692    325.0  0.711101  0.547692\n",
      "Normalized confusion matrix\n",
      "[[0.84       0.04       0.12      ]\n",
      " [0.73417722 0.02531646 0.24050633]\n",
      " [0.48979592 0.05102041 0.45918367]]\n",
      "              f1-score  precision    recall  support       roc  accuracy\n",
      "r12           0.686916   0.581028  0.840000    175.0  0.684939  0.551136\n",
      "r3            0.043011   0.142857  0.025316     79.0  0.531877  0.551136\n",
      "r45           0.491803   0.529412  0.459184     98.0  0.694962  0.551136\n",
      "micro avg     0.551136   0.551136  0.551136    352.0  0.639576  0.551136\n",
      "macro avg     0.407243   0.417766  0.441500    352.0  0.639576  0.551136\n",
      "weighted avg  0.488082   0.468318  0.551136    352.0  0.639576  0.551136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Setup a list of processes that we want to run\n",
    "processes = [mp.Process(target=run, args=(x[0], x[1], output)) for x in args]\n",
    "\n",
    "# Run processes\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "# Exit the completed processes\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "# Get process results from the output queue\n",
    "results = [output.get() for p in processes]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
