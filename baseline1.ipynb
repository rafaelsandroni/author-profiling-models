{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from functions.models import \n",
    "from functions.datasets import getDatasets\n",
    "from functions.metrics import evaluator\n",
    "from functions.plot import ROC, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = 'baseline1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'pan13_en'\n",
    "task = 'age'\n",
    "\n",
    "def getBestParams(task, dataset_name):\n",
    "    \n",
    "    dataset_name = dataset_name.strip().lower()\n",
    "    task = task.strip().lower()\n",
    "    \n",
    "    # load excel params\n",
    "    baseline1 = pd.read_excel('./Reports/Reports.xlsx', baseline)\n",
    "    baseline1['Task'] = baseline1['Task'].str.lower()\n",
    "    baseline1['Name'] = baseline1['Name'].str.lower()\n",
    "    \n",
    "    best_params = baseline1[(baseline1['Name'] == dataset_name) & (baseline1['Task'] == task)]\n",
    "    \n",
    "    max_features = best_params['max features'].values[0]\n",
    "    \n",
    "    model_params = {\n",
    "                    'vect__max_features': max_features if max_features != 'None' and not pd.isna(max_features) else None,\n",
    "                    'vect__max_df': best_params['max df'].values[0] if not pd.isna(best_params['max df'].values[0]) else 1,\n",
    "                    'clf__C': best_params['C'].values[0] if not pd.isna(best_params['C'].values[0]) else 1000.0, \n",
    "                    'clf__penalty': best_params['P'].values[0] if not pd.isna(best_params['P'].values[0]) else 'l2'\n",
    "                    }\n",
    "    \n",
    "    return model_params\n",
    "\n",
    "getBestParams(task, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoder(y):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y)\n",
    "\n",
    "    return (le.transform(y), len(le.classes_), list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    space = ' '    \n",
    "    for char in ['\\n','-', '...', '*', '/', '+', '\\\\']:\n",
    "        text = text.replace(char, space)\n",
    "        \n",
    "    text = text.replace(space*2, space)\n",
    "    text = text.replace(space*3, space)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform classification for each problem / task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, y, n_classes, classes_name, params):\n",
    "                \n",
    "    pipeline = Pipeline([       \n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),        \n",
    "        ('clf', LogisticRegression(verbose=1)),\n",
    "    ])\n",
    "    \n",
    "    # pipeline.set_params(**params)    \n",
    "    vect = TfidfVectorizer(max_features=params.get('vect__max_features'), max_df=params.get('vect__max_df'))\n",
    "    \n",
    "    K = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    t0 = time()\n",
    "    \n",
    "    predicted_y = []\n",
    "    expected_y = []    \n",
    "    score_y = []\n",
    "    \n",
    "    for train_index, test_index in K.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        X_train = vect.fit_transform(X_train)\n",
    "        X_test = vect.transform(X_test)\n",
    "        \n",
    "        clf = LogisticRegression(C=params.get('clf__C'), penalty=params.get('clf__penalty'), solver='liblinear')\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        predicted_y.extend(clf.predict(X_test))\n",
    "        expected_y.extend(y_test)\n",
    "        score_y.extend(clf.predict_proba(X_test))\n",
    "\n",
    "        ### get train score\n",
    "\n",
    "    # print(\"done in %0.2fs and %0.1fmin\" % ((time() - t0), ((time() - t0) / 60) ))\n",
    "    # print()\n",
    "    \n",
    "    report = pd.DataFrame(classification_report(expected_y, predicted_y, digits=5, target_names=classes_name, output_dict=True))\n",
    "    report = report.transpose()\n",
    "    \n",
    "    return (\n",
    "        report, \n",
    "        np.asarray(expected_y),\n",
    "        np.asarray(predicted_y),\n",
    "        np.asarray(score_y)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(task, dataset_name, output = None):    \n",
    "    datasets = getDatasets(task,'df', dataset_name)\n",
    "    for i in datasets.iterrows():\n",
    "\n",
    "        name = i[1]['dataset_name']\n",
    "        label = task\n",
    "        ds_path = i[1]['path']\n",
    "\n",
    "        # load training and test dataframes\n",
    "        training_path = ds_path + '/' + i[1]['training']        \n",
    "\n",
    "        df_training = pd.read_csv(training_path)#, usecols=cols)        \n",
    "\n",
    "        df_training['text'] = df_training['text'].apply(clean)\n",
    "        X_train = df_training['text'].values\n",
    "        y_train, n_classes, classes_name = labelEncoder(df_training[label].values)\n",
    "\n",
    "        # del(df_training)\n",
    "\n",
    "        # print(\"Dataset: {0} and task: {1}\".format(name, label))\n",
    "\n",
    "        # print(\"n_classes: {0}\".format(n_classes))\n",
    "\n",
    "        params = getBestParams(task, dataset_name)\n",
    "        # print(\"params: \", params)\n",
    "\n",
    "        report, expected_y, predicted_y, score_y = model(X_train, y_train, n_classes, classes_name, params)\n",
    "\n",
    "        # get ROC\n",
    "        dataset_name = dataset_name + '/' + baseline\n",
    "        \n",
    "        roc_c = ROC(expected_y, score_y, n_classes, task, dataset_name, classes_name)\n",
    "        report['roc'] = list(roc_c.values()) + [roc_c['macro']] * 2\n",
    "\n",
    "        # compute accuracy\n",
    "        accuracy = accuracy_score(expected_y, predicted_y)\n",
    "        report['accuracy'] = [accuracy] * (n_classes + 3)\n",
    "\n",
    "        # compute confusion matrix\n",
    "        c_matrix = confusion_matrix(expected_y, predicted_y)\n",
    "        plot_confusion_matrix(c_matrix, classes_name, task, dataset_name, True)\n",
    "        cm = pd.DataFrame(c_matrix, columns=classes_name, index=classes_name)\n",
    "\n",
    "        directory = './Reports/' + task + '/' + dataset_name + '/'\n",
    "        report.to_csv(directory + 'report.csv')\n",
    "        cm.to_csv(directory + 'confusion_matrix.csv')    \n",
    "\n",
    "        print(report)\n",
    "\n",
    "        # output.put('results for {0} and {1}'.format(task, dataset_name))\n",
    "        # output.put(report.to_dict())\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import random\n",
    "import string\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "# Define an output queue\n",
    "output = mp.Queue()\n",
    "\n",
    "task_list = ['relig','polit','education','professional','region','TI']#,'gender','age']\n",
    "dataset_list = ['brmoral','b5post','esic','brblogset','enblogs','pan13_en','pan13_es','sms']\n",
    "\n",
    "args = []\n",
    "for task in task_list:\n",
    "    for ds in dataset_list:\n",
    "        d = getDatasets(task,'df', ds)\n",
    "        if len(d.values) > 0:\n",
    "            args.append([task, ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a list of processes that we want to run\n",
    "processes = [mp.Process(target=run, args=(x[0], x[1], output)) for x in args]\n",
    "\n",
    "# Run processes\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "# Exit the completed processes\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "# Get process results from the output queue\n",
    "results = [output.get() for p in processes]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
