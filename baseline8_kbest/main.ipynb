{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.functions.preprocessing import clean, labelEncoder\n",
    "from Models.functions.datasets import loadTrainTest\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression, f_classif\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    features_maps = [50,50],\n",
    "    kernel_size = [3,4],\n",
    "    strides = [1,1],\n",
    "    dropout_rate = 0.3,\n",
    "    epochs = 100,\n",
    "    batch_size = 32,\n",
    "    embedding_dim = 100,\n",
    "    max_seq_length = 500,\n",
    "    max_num_words = 150000,\n",
    "    pool_size = [2,2,2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# Synthetic Minority Oversampling Technique (SMOTE)\n",
    "def oversampling(X, y):\n",
    "    try:\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "    except:        \n",
    "        X_resampled, y_resampled = X, y\n",
    "        \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "root= '/home/rafael/Dataframe/'\n",
    "dataset_name = 'brmoral'\n",
    "lang = 'pt'\n",
    "task = 'education'\n",
    "reglog = LogisticRegression(C=100, penalty='l2', multi_class='auto', class_weight='balanced', solver='liblinear')\n",
    "\n",
    "X, _, y, _ = loadTrainTest(task, dataset_name, root, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Como direito individual , cada ser humano tem o direito de escolha de preferência de gênero , assim como direito ao matrimônio . Logo é dever da lei em cumprir o direito e liberdade de livre arbítrio '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(clean, lang=lang)\n",
    "X = X.values # mandatory for pan13\n",
    "\n",
    "y, n_classes, classes_names = labelEncoder(y)\n",
    "params['n_classes'] = n_classes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# feature transform\n",
    "vect = TfidfVectorizer(max_features=None, ngram_range=(1,1), analyzer='word').fit(X_train)\n",
    "\n",
    "X_train = vect.transform(X_train)\n",
    "\n",
    "clf = reglog.fit(X_train, y_train)       \n",
    "\n",
    "# test\n",
    "X_test1 = vect.transform(X_test)\n",
    "predicted = clf.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]), (87, 8434))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.toarray(), X_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cada indivíduo liberdade escolher deseja passar vida união matrimonial , basta existir sentimento mútuo amor entendimento , necessariamente sexos opostos . , grande problema porte armas brasil , é fato vivemos cultura ódio sociedade , , posse armas legalizada , ainda muitos casos homicídios , acredito legalização armas , número somente irá crescer exponencialmente . , cabe cada indivíduo decidir irá fazer vida filho irá conceber , realidade , acredito decisão extremamente difícil delicada mãe , optar aborto , cabe estado negar opção mulheres , pois legalizado , existem clinicas clandestinas fazem operação muitas vezes colocam vida dois risco . , \" pena morte é \" \" saída \" \" cruel irresponsável parte estado , pois sistema carcerário é precário sobrecarregado diversos fatores , necessidades básicas deveriam ser oferecidas estado saúde , educação moradia , nega fornecer , melhor dizendo , oferece forma totalmente precária deixando população carente mercê sorte . muitas vezes alternativa , obviamente isenta cometeram crimes , porque sempre existem opções , acredito sistema tenta reincluir indivíduo sociedade invés deixa-lo cada vez margem , melhor humano . \" , acredito caso bebidas alcoólicas cigarro , drogas , estado consegue taxar impostos , obtendo retorno financeiro , invés gastar combate tráfego maconha . , hoje dia jovem 16 possui mentalidade consciente , teoricamente , pode ser protegido idade , caso cometa crime , ser considerado menor idade . , é solução fornece realmente mudança sociedade , pois apenas permite entrada dessas pessoas universidades , muitas vezes conhecimento básico continuidade faculdade . analogia colocar band aid hemorragia . melhor disponibilizar educação básica qualidade . , igreja consegue arrecadar verbas , então possui movimento financeiro portanto gera lucros , logo faz sentido pagar dinheiro .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, array(['s012', 's3', 's4'], dtype=object))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[0], classes_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(vect.transform([\"minha educasao fui muito ruim, n tive opurtunidade de estudar\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "root= '/home/rafael/Dataframe/'\n",
    "dataset_name = 'brblogset'\n",
    "lang = 'pt'\n",
    "task = 'education'\n",
    "reglog = LogisticRegression(C=100, penalty='l2', multi_class='auto', class_weight='balanced', solver='liblinear')\n",
    "\n",
    "X, _, y, _ = loadTrainTest(task, dataset_name, root, lang)\n",
    "\n",
    "# small sample\n",
    "\n",
    "X = X.apply(clean, lang=lang)\n",
    "X = X.values # mandatory for pan13\n",
    "\n",
    "y, n_classes, classes_names = labelEncoder(y)\n",
    "params['n_classes'] = n_classes\n",
    "\n",
    "max_length = np.max([len(x.split(\" \")) for x in X])\n",
    "mean_length = int(np.mean([len(x.split(\" \")) for x in X]))\n",
    "median_length = int(np.median([len(x.split(\" \")) for x in X]))\n",
    "\n",
    "\n",
    "\n",
    "X_resampled, y_resampled = oversampling(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled)\n",
    "# feature transform\n",
    "vect = TfidfVectorizer(max_features=None, ngram_range=(1,1), analyzer='word').fit(X_train)\n",
    "\n",
    "X_train = vect.transform(X_train)\n",
    "\n",
    "clf = reglog.fit(X_train, y_train)       \n",
    "\n",
    "# test\n",
    "X_test = vect.transform(X_test)\n",
    "predicted = clf.predict(X_test)\n",
    "    #print(classification_report(y_test, predicted))\n",
    "    print(\"without k-best {0}\".format(f1_score(y_test, predicted, average='weighted')))\n",
    "\n",
    "    predicted1 = []\n",
    "    expected1 = []\n",
    "\n",
    "    predicted2 = []\n",
    "    expected2 = []\n",
    "\n",
    "    max_features = 130000\n",
    "\n",
    "    steps = 10000\n",
    "\n",
    "    kvalues = [i for i in range(500, max_features, steps)]\n",
    "    kvalues.append('all')\n",
    "\n",
    "    for kvalue in kvalues:\n",
    "        K = StratifiedKFold(n_splits=3)    \n",
    "\n",
    "        # Cross validation KFolds\n",
    "        for train_index, test_index in K.split(X, y):\n",
    "\n",
    "            X_resampled, y_resampled = oversampling(X, y)\n",
    "\n",
    "            X_train, X_test = X_resampled[train_index], X_resampled[test_index]\n",
    "            y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "\n",
    "            # feature transform\n",
    "            vect = TfidfVectorizer(max_features=max_features, ngram_range=(1,1), analyzer='word').fit(X_train)\n",
    "            X_train = vect.transform(X_train).toarray()\n",
    "\n",
    "            # feature selection\n",
    "            sel = SelectKBest(k_best_func,k=kvalue)\n",
    "            ft = sel.fit(X_train, y_train)\n",
    "            train_best = ft.transform(X_train)\n",
    "\n",
    "            # train\n",
    "            clf1 = reglog.fit(train_best, y_train)\n",
    "\n",
    "            # test\n",
    "            X_test = vect.transform(X_test).toarray()\n",
    "            test_best = ft.transform(X_test)\n",
    "            pred = clf1.predict(test_best)\n",
    "\n",
    "            expected1.extend(y_test)\n",
    "            predicted1.extend(pred)        \n",
    "\n",
    "        #print(classification_report(y_test, predicted))    \n",
    "        print(\"kvalue {0} f1score {1}\".format(kvalue, f1_score(expected1, predicted1, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi2, f_regression, f_classif\n",
    "#test(chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test(f_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test(f_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blinded Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "root= '/home/rafael/Dataframe/'\n",
    "dataset_name = 'brblogset'\n",
    "lang = 'pt'\n",
    "task = 'education'\n",
    "reglog = LogisticRegression(C=100, penalty='l2', multi_class='auto', class_weight='balanced', solver='liblinear')\n",
    "\n",
    "X, _, y, _ = loadTrainTest(task, dataset_name, root, lang)\n",
    "\n",
    "# small sample\n",
    "X = X.apply(clean, lang=lang)\n",
    "#X = X.values # mandatory for pan13\n",
    "\n",
    "y, n_classes, classes_names = labelEncoder(y)    \n",
    "params['n_classes'] = n_classes\n",
    "\n",
    "max_length = np.max([len(x.split(\" \")) for x in X])\n",
    "mean_length = int(np.mean([len(x.split(\" \")) for x in X]))\n",
    "median_length = int(np.median([len(x.split(\" \")) for x in X]))\n",
    "\n",
    "params['max_seq_length'] = int(mean_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Básico\n",
      "1 1 1 1\n",
      "1 1 1 1\n",
      "1 1 1 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.34      0.46      1011\n",
      "           1       0.57      0.88      0.69      1011\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      2022\n",
      "   macro avg       0.65      0.61      0.58      2022\n",
      "weighted avg       0.65      0.61      0.58      2022\n",
      "\n",
      "[[343 668]\n",
      " [124 887]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-92b09bdc7895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcurrent_class\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0my_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0monevsrest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-92b09bdc7895>\u001b[0m in \u001b[0;36monevsrest\u001b[0;34m(X, y_a)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1score {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "def onevsrest(X, y_a):\n",
    "    max_features = 130000\n",
    "\n",
    "    K = StratifiedKFold(n_splits=3)\n",
    "    \n",
    "    expected1 = []\n",
    "    predicted1 = []\n",
    "    \n",
    "    # Cross validation KFolds\n",
    "    for train_index, test_index in K.split(X, y_a):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y_a[train_index], y_a[test_index]\n",
    "        \n",
    "        # feature transform\n",
    "        vect = TfidfVectorizer(max_features=None, ngram_range=(1,1), analyzer='word').fit(X_train)\n",
    "        X_train = vect.transform(X_train).toarray()\n",
    "        X_test = vect.transform(X_test).toarray()\n",
    "\n",
    "        X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "        X_test, y_test = SMOTE().fit_resample(X_test, y_test)\n",
    "        \n",
    "        print(len(np.where(y_train == 0)), len(np.where(y_train == 1)), len(np.where(y_test == 0)), len(np.where(y_test == 1)))\n",
    "\n",
    "        # train\n",
    "        clf1 = reglog.fit(X_train, y_train)\n",
    "\n",
    "        # test    \n",
    "        pred = clf1.predict(X_test)\n",
    "\n",
    "        expected1.extend(y_test)\n",
    "        predicted1.extend(pred)        \n",
    "\n",
    "    print(classification_report(expected1, predicted1))    \n",
    "    print(confusion_matrix(expected1, predicted1))    \n",
    "    print(\"f1score {1}\".format(f1_score(expected1, predicted1, average='weighted')))\n",
    "    \n",
    "    \n",
    "\n",
    "current_class = 0\n",
    "print(\"Class {0}\".format(classes_names[current_class]))\n",
    "labels = lambda x: 1 if x != current_class else 0\n",
    "y_a = np.array(list(map(labels, y)))\n",
    "onevsrest(X, y_a)\n",
    "\n",
    "\n",
    "current_class = 1\n",
    "print(\"Class {0}\".format(classes_names[current_class]))\n",
    "labels = lambda x: 1 if x != current_class else 0\n",
    "y_a = np.array(list(map(labels, y)))\n",
    "onevsrest(X, y_a)\n",
    "\n",
    "current_class = 2\n",
    "print(\"Class {0}\".format(classes_names[current_class]))\n",
    "labels = lambda x: 1 if x != current_class else 0\n",
    "y_a = np.array(list(map(labels, y)))\n",
    "onevsrest(X, y_a)\n",
    "\n",
    "current_class = 3\n",
    "print(\"Class {0}\".format(classes_names[current_class]))\n",
    "labels = lambda x: 1 if x != current_class else 0\n",
    "y_a = np.array(list(map(labels, y)))\n",
    "onevsrest(X, y_a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_features=None, ngram_range=(1,1), analyzer='word').fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cafua': 34126,\n",
       " 'feijoada': 77463,\n",
       " 'meada': 113404,\n",
       " 'inexisto': 95621,\n",
       " 'semicantão': 155368,\n",
       " 'maisnova': 110261,\n",
       " 'luzir': 109139,\n",
       " 'xylitol': 179333,\n",
       " 'er': 69686,\n",
       " 'honrados': 90855,\n",
       " 'requisitada': 147825,\n",
       " 'naji': 120107,\n",
       " 'correremos': 48529,\n",
       " 'ode': 124232,\n",
       " 'detenções': 58681,\n",
       " 'chavista': 39341,\n",
       " 'intímas': 98480,\n",
       " 'modificava': 116975,\n",
       " 'botinha': 31492,\n",
       " 'cotação': 49037,\n",
       " 'observamos': 123787,\n",
       " 'perestrello': 131289,\n",
       " 'naysa': 120691,\n",
       " 'iyá': 100050,\n",
       " 'emagrece': 65529,\n",
       " 'trôpegos': 170838,\n",
       " 'idyllic': 92367,\n",
       " 'bloise': 30442,\n",
       " 'morarmos': 117777,\n",
       " 'desmotivadas': 57554,\n",
       " 'despachou': 57739,\n",
       " 'óxido': 181149,\n",
       " 'sitiou': 158199,\n",
       " 'rocs': 150488,\n",
       " 'ei20048': 64678,\n",
       " 'sérgia': 163719,\n",
       " '32ºc': 5553,\n",
       " 'financiei': 78772,\n",
       " 'conjug': 45766,\n",
       " 'musqueira': 119363,\n",
       " 'supramencionados': 162881,\n",
       " 'gwen': 87794,\n",
       " 'especializado': 71396,\n",
       " 'nhã': 121699,\n",
       " 'conectadas': 45112,\n",
       " 'moderadamente': 116900,\n",
       " 'bioe': 29763,\n",
       " 'englishness': 67888,\n",
       " 'improbabilidade': 93916,\n",
       " 'direcionadores': 60257,\n",
       " 'воли': 181543,\n",
       " 'satis': 153763,\n",
       " 'azz': 26068,\n",
       " 'processamento': 138229,\n",
       " 'monetária': 117326,\n",
       " 'refrigerador': 145674,\n",
       " '1945em': 2691,\n",
       " 'comunicativas': 44404,\n",
       " 'savages': 153923,\n",
       " 'salalho': 152728,\n",
       " 'tempurá': 165717,\n",
       " 'granar': 86420,\n",
       " '7213': 7959,\n",
       " 'territórios': 166303,\n",
       " 'negociações': 121025,\n",
       " '8fmbq': 8581,\n",
       " 'alzira': 16548,\n",
       " 'cs6': 50471,\n",
       " 'agorame': 13973,\n",
       " 'ingenuamente': 96170,\n",
       " 'rahmati': 142706,\n",
       " 'jurina': 102094,\n",
       " 'wgf1nfwbbua': 178325,\n",
       " 'compará': 43713,\n",
       " 'incomodadas': 94606,\n",
       " 'custamos': 51274,\n",
       " 'dermatite': 54987,\n",
       " 'despojareis': 57932,\n",
       " 'issued': 99685,\n",
       " 'homes': 90686,\n",
       " 'entusiásticos': 69012,\n",
       " 'matriculados': 112914,\n",
       " 'revisado': 149375,\n",
       " 'magney': 110012,\n",
       " 'fascinou': 76894,\n",
       " 'zaga': 179788,\n",
       " 'interleukin': 97866,\n",
       " 'destina': 58259,\n",
       " '70mb': 7909,\n",
       " 'pastom': 129383,\n",
       " 'theiss': 166722,\n",
       " 'pirâmides': 133431,\n",
       " 'embasarem': 65726,\n",
       " 'proac': 138105,\n",
       " 'preparatórios': 137076,\n",
       " 'entregaremos': 68795,\n",
       " 'termogênica': 166192,\n",
       " 'respeitaremos': 148168,\n",
       " 'sísifo': 163796,\n",
       " 'ressuscitando': 148467,\n",
       " 'acético': 11947,\n",
       " 'retardatário': 148728,\n",
       " 'simbolizará': 157543,\n",
       " 'chona': 39900,\n",
       " 'pindamonhangaba': 133093,\n",
       " 'geofusion': 84353,\n",
       " 'charminho': 39228,\n",
       " 'thang': 166658,\n",
       " 'tunis': 171096,\n",
       " 'pernoite': 131724,\n",
       " '3p4': 6411,\n",
       " 'citocinese': 40973,\n",
       " 'testarem': 166422,\n",
       " 'variando': 174063,\n",
       " 'pavê1': 129876,\n",
       " 'demonstrará': 54343,\n",
       " 'surrupiadores': 163102,\n",
       " 'dad': 51833,\n",
       " 'alcar': 15101,\n",
       " '3621': 6018,\n",
       " '746': 8014,\n",
       " 'muestras': 118739,\n",
       " 'memesinspiradas': 114072,\n",
       " 'divulgaçãosão': 61594,\n",
       " 'jacaraú': 100154,\n",
       " 'idalina': 92134,\n",
       " 'desapreço': 55492,\n",
       " 'barbeiro': 27295,\n",
       " 'prefaciado': 136678,\n",
       " 'precedido': 136403,\n",
       " '17749': 2306,\n",
       " 'kleist': 103419,\n",
       " 'dissiparia': 61048,\n",
       " 'lawford': 105296,\n",
       " 'intervalados': 98149,\n",
       " 'bypassados': 33430,\n",
       " 'caputira': 35880,\n",
       " 'cambia': 34778,\n",
       " 'desfilam': 56983,\n",
       " 'aedin': 13043,\n",
       " 'nto': 122944,\n",
       " 'salvos': 153019,\n",
       " 'esso': 72143,\n",
       " 'motivador': 118283,\n",
       " 'миротворческое': 182157,\n",
       " 'enleados': 68092,\n",
       " 'rogo': 150678,\n",
       " 'ameiiii': 17112,\n",
       " 'transmutarão': 169438,\n",
       " 'reindustrialização': 146182,\n",
       " 'auspiciosa': 24949,\n",
       " 'jaracaty': 100535,\n",
       " 'rate': 143246,\n",
       " 'amadora': 16641,\n",
       " 'comemorações': 43148,\n",
       " 'ólafsvík': 181085,\n",
       " 'ógeas': 181080,\n",
       " 'spaceboypara': 160179,\n",
       " 'priore': 137947,\n",
       " 'ananias': 17761,\n",
       " 'engulo': 68012,\n",
       " 'rakyat': 142803,\n",
       " 'axônios': 25907,\n",
       " 'vidaalém': 175657,\n",
       " 'sankur': 153334,\n",
       " '1431244996901362': 1633,\n",
       " 'enpj': 68181,\n",
       " 'apurou': 20825,\n",
       " 'conectomas': 45128,\n",
       " 'anatomicamente': 17812,\n",
       " '02sara': 261,\n",
       " 'ossificados': 126458,\n",
       " 'ninja': 121969,\n",
       " 'flanqueado': 79366,\n",
       " 'aécio': 26139,\n",
       " 'empilhadores': 66298,\n",
       " 'carrie': 36615,\n",
       " 'важность': 181457,\n",
       " 'robustus': 150403,\n",
       " 'ifr': 92465,\n",
       " 'frayed': 81358,\n",
       " 'wolneyf': 178735,\n",
       " 'cywiner': 51459,\n",
       " 'fenilcetonúrico': 77710,\n",
       " '37462495': 6188,\n",
       " 'higa': 89905,\n",
       " 'chimbinho': 39726,\n",
       " 'rispidamente': 150166,\n",
       " 'nefasto': 120910,\n",
       " 'sobriamente': 158865,\n",
       " 'mochilinha': 116830,\n",
       " 'curou': 51103,\n",
       " 'countersteer': 49122,\n",
       " 'estátuas': 73321,\n",
       " 'ditoso': 61336,\n",
       " 'kuwae': 103989,\n",
       " 'piscos': 133484,\n",
       " 'engajem': 67732,\n",
       " 'gregos': 86752,\n",
       " 'lembram': 105815,\n",
       " 'caixinha': 34265,\n",
       " 'esconjuro': 70484,\n",
       " 'inframundo': 96095,\n",
       " 'scrub': 154481,\n",
       " 'divinos': 61515,\n",
       " 'conradiano': 45921,\n",
       " 'liverpoolbarcelona': 107619,\n",
       " 'ecmab': 63893,\n",
       " 'fraser': 81296,\n",
       " 'жадность': 181779,\n",
       " 'desfilou': 56998,\n",
       " 'delayer': 53838,\n",
       " 'cinematogr': 40579,\n",
       " 'trágica': 170780,\n",
       " 'nº88': 123253,\n",
       " 'minimalismo': 116021,\n",
       " 'kassem': 102710,\n",
       " 'sessue': 156346,\n",
       " 'ffffff': 78132,\n",
       " 'brancogerminados': 31817,\n",
       " '70486': 7892,\n",
       " 'gravávamos': 86651,\n",
       " 'escarnecimento': 70264,\n",
       " 'subconscious': 161382,\n",
       " 'blush': 30535,\n",
       " 'relatado': 146445,\n",
       " 'sql': 160519,\n",
       " 'paroupara': 128799,\n",
       " 'rente': 147114,\n",
       " 'risqué': 150174,\n",
       " 'innatis': 96511,\n",
       " 'vault': 174245,\n",
       " 'cogniscível': 42224,\n",
       " 'conjuntosjardim': 45802,\n",
       " 'lorena': 108296,\n",
       " 'elogiável': 65402,\n",
       " 'mummy': 119048,\n",
       " 'luvaria': 109083,\n",
       " '4311': 6610,\n",
       " 'grifado': 86821,\n",
       " 'psíquicos': 140304,\n",
       " 'preocupemos': 137028,\n",
       " 'jajá': 100297,\n",
       " 'bomb': 30951,\n",
       " 'fingimentos': 78847,\n",
       " 'ociosos': 124074,\n",
       " 'engajados': 67723,\n",
       " 'parnitparnitparnit': 128776,\n",
       " 'incidindo': 94437,\n",
       " 'turmeric': 171214,\n",
       " 'ecodebate': 63918,\n",
       " 'interpela': 97993,\n",
       " 'glau': 85340,\n",
       " 'catalizou': 37204,\n",
       " 'lisandra': 107407,\n",
       " 'fixadoras': 79220,\n",
       " '7x': 8225,\n",
       " 'netus': 121411,\n",
       " 'trombada': 170535,\n",
       " '6320': 7595,\n",
       " 'gildemar': 84995,\n",
       " '911': 8668,\n",
       " 'postiço': 135801,\n",
       " 'vitimizada': 176612,\n",
       " 'cauteloso': 37562,\n",
       " 'conduziam': 45080,\n",
       " 'wilame': 178474,\n",
       " 'jak2': 100299,\n",
       " 'mínimos': 119749,\n",
       " 'corresponsabilidade': 48570,\n",
       " 'lizzie': 107738,\n",
       " 'rune': 151755,\n",
       " 'textão': 166575,\n",
       " 'abf': 9804,\n",
       " 'bocaquem': 30663,\n",
       " 'talher': 164257,\n",
       " 'strong': 161176,\n",
       " 'progredirá': 138728,\n",
       " 'multipartidário': 118943,\n",
       " 'florales': 79567,\n",
       " 'atingidas': 24049,\n",
       " 'excepcionalismo': 74339,\n",
       " 'sabrán': 152268,\n",
       " 'escalaminhadas': 70108,\n",
       " 'yonggi': 179598,\n",
       " 'goleia': 85745,\n",
       " 'ariely': 21530,\n",
       " 'frio': 81690,\n",
       " 'larissambfg': 104937,\n",
       " 'sinonimo': 157926,\n",
       " 'absorvedores': 10328,\n",
       " 'myrka': 119531,\n",
       " 'nº2165': 123238,\n",
       " 'aquelo': 20926,\n",
       " 'consultoras': 46647,\n",
       " 'guisados': 87610,\n",
       " 'suavizai': 161326,\n",
       " 'ever20': 73928,\n",
       " 'sensibilizando': 155637,\n",
       " 'munayniyoq': 119055,\n",
       " 'superheroínas': 162608,\n",
       " 'lágio': 109240,\n",
       " 'tecnog': 165206,\n",
       " 'consciousnes': 45984,\n",
       " 'corintianas': 48286,\n",
       " 'biometria': 29835,\n",
       " 'condenarem': 44927,\n",
       " 'encorajada': 67160,\n",
       " 'estelíferas': 72523,\n",
       " 'eydie': 75807,\n",
       " 'medplexx': 113686,\n",
       " 'segregação': 154940,\n",
       " 'inviolável': 98815,\n",
       " 'preservarei': 137279,\n",
       " 'escaladasimétrica': 70103,\n",
       " 'desabado': 55140,\n",
       " 'leif': 105699,\n",
       " 'sitrans': 158206,\n",
       " 'impedidas': 93381,\n",
       " 'iniqüidade': 96412,\n",
       " 'danizio': 52166,\n",
       " 'atemorizada': 23847,\n",
       " 'quicar': 141969,\n",
       " 'encaixarão': 66706,\n",
       " 'indispor': 95319,\n",
       " 'cronificada': 50174,\n",
       " 'naufrago': 120610,\n",
       " 'mimnessas': 115834,\n",
       " 'porteira': 135407,\n",
       " 'triunfará': 170423,\n",
       " 'retrata': 148925,\n",
       " 'abeac': 9709,\n",
       " 'items': 99860,\n",
       " 'proibida': 138767,\n",
       " 'basta': 27730,\n",
       " 'cyathus': 51407,\n",
       " 'enlouquecidas': 68116,\n",
       " 'chargersforam': 39185,\n",
       " 'tyrannosaurus': 171436,\n",
       " 'iaculis': 91832,\n",
       " 'dublagem': 63022,\n",
       " 'rouca': 151316,\n",
       " 'gisberta': 85219,\n",
       " 'ocasionado': 123987,\n",
       " 'sul21': 162310,\n",
       " 'completados': 43894,\n",
       " 'radford': 142524,\n",
       " 'juliosevero': 101913,\n",
       " 'califórnio': 34528,\n",
       " 'funebom': 82361,\n",
       " '15logo': 1964,\n",
       " 'perdição': 131168,\n",
       " 'acadêmicas': 10583,\n",
       " 'insignificância': 96845,\n",
       " 'zilah': 180183,\n",
       " 'dolares': 62037,\n",
       " 'fb_action_ids': 77233,\n",
       " 'amásia': 17591,\n",
       " 'espoletado': 71793,\n",
       " 'arsênyi': 22442,\n",
       " 'ideflor': 92186,\n",
       " 'akron': 14794,\n",
       " 'lifi': 106828,\n",
       " 'roth': 151235,\n",
       " 'pulverizando': 140631,\n",
       " '____________________________após': 9182,\n",
       " 'principalidades': 137897,\n",
       " 'marcante': 111649,\n",
       " 'amansa': 16751,\n",
       " 'guardarás': 87301,\n",
       " 'crie': 49827,\n",
       " 'enrica': 68253,\n",
       " 'ologun': 124975,\n",
       " 'alimentarcadeia': 15759,\n",
       " 'pedisse': 130229,\n",
       " 'associaçãointernacionalpoetasdelmundo': 23443,\n",
       " 'pouquíssimas': 136002,\n",
       " 'unthinkable': 172716,\n",
       " 'floridos': 79639,\n",
       " 'serei': 156007,\n",
       " 'pot': 135842,\n",
       " 'escudeiro': 70718,\n",
       " 'desiludidas': 57168,\n",
       " 'axei': 25880,\n",
       " 'desanimados': 55414,\n",
       " 'каждого': 181937,\n",
       " 'contemplade': 46866,\n",
       " 'geniosa': 84196,\n",
       " 'indignem': 95261,\n",
       " 'hipertireodismo': 90136,\n",
       " 'pensaram': 130792,\n",
       " 'quirinius': 142151,\n",
       " 'estivermos': 72796,\n",
       " 'atabalhoadamente': 23728,\n",
       " 'bandeirantes': 27037,\n",
       " 'andaluza': 17896,\n",
       " 'espacio': 71199,\n",
       " 'midiota': 115440,\n",
       " 'bombardeio': 30973,\n",
       " '7803': 8123,\n",
       " 'clever': 41466,\n",
       " 'fitossociologia': 79185,\n",
       " 'enlouqueceram': 68110,\n",
       " 'pauli': 129714,\n",
       " '2416': 4047,\n",
       " 'mentirinha': 114389,\n",
       " 'aprendizagens': 20473,\n",
       " 'radiopajeu': 142618,\n",
       " 'sanb11': 153151,\n",
       " 'canônico': 35553,\n",
       " 'representarem': 147543,\n",
       " 'indizível': 95379,\n",
       " 'anônimos': 19377,\n",
       " 'primeira': 137811,\n",
       " 'waterfall': 177993,\n",
       " 'jingobel': 101024,\n",
       " 'jaeger': 100246,\n",
       " 'cantareira': 35444,\n",
       " 'gueta': 87460,\n",
       " 'spire': 160369,\n",
       " 'caderninhos': 34021,\n",
       " 'kurban': 103940,\n",
       " 'elkerson': 65334,\n",
       " 'pesquisaqualitativa': 132264,\n",
       " 'sofisticado': 159091,\n",
       " 'usufruídas': 173154,\n",
       " 'redescritos': 145022,\n",
       " 'treine': 169922,\n",
       " 'thin': 166842,\n",
       " 'evidência': 73989,\n",
       " 'lojinhas': 108095,\n",
       " 'contratona': 47373,\n",
       " 'kaneku': 102548,\n",
       " 'cursava': 51141,\n",
       " 'prince': 137877,\n",
       " 'freddie': 81385,\n",
       " 'cavour': 37681,\n",
       " '3636': 6035,\n",
       " 'recirculação': 144272,\n",
       " 'invalidais': 98557,\n",
       " 'takaraka': 164193,\n",
       " 'sentirsentir': 155786,\n",
       " 'cocos': 42060,\n",
       " 'furious': 82468,\n",
       " 'caiçara': 34275,\n",
       " '35x24': 5987,\n",
       " 'desalentadas': 55351,\n",
       " 'fisco': 79056,\n",
       " 'preencho': 136670,\n",
       " 'carreatas': 36559,\n",
       " 'implemento': 93597,\n",
       " 'puxadores': 140909,\n",
       " 'maracá': 111544,\n",
       " 'paisagistas': 127489,\n",
       " 'felizeu': 77600,\n",
       " 'amortecida': 17421,\n",
       " 'aminna': 17259,\n",
       " 'baruki': 27598,\n",
       " 'traumas': 169740,\n",
       " 'impetrar': 93524,\n",
       " 'dramaticidade': 62718,\n",
       " '12km': 1341,\n",
       " 'sopinhas': 159785,\n",
       " '3397': 5681,\n",
       " 'destravando': 58336,\n",
       " 'vantress': 173978,\n",
       " 'attitude': 24556,\n",
       " 'pinhas': 133141,\n",
       " 'desestruture': 56889,\n",
       " 'toquei': 168156,\n",
       " 'direcione': 60273,\n",
       " 'incentivadas': 94359,\n",
       " 'itaquá1º': 99830,\n",
       " 'menosprezando': 114287,\n",
       " 'espelha': 71498,\n",
       " 'obtinham': 123934,\n",
       " 'tribunahoje': 170119,\n",
       " 'romantica': 150825,\n",
       " 'uriah': 172890,\n",
       " 'remeleixo': 146760,\n",
       " 'teravançado': 166054,\n",
       " 'destilam': 58252,\n",
       " 'seremos': 156018,\n",
       " 'prima': 137777,\n",
       " 'zu': 180383,\n",
       " 'vacantes': 173383,\n",
       " 'ceomar': 38422,\n",
       " 'lançando': 104799,\n",
       " 'uol': 172749,\n",
       " 'sedgewick': 154774,\n",
       " 'jessier': 100881,\n",
       " '4562': 6706,\n",
       " 'filia': 78509,\n",
       " 'wanderlust': 177877,\n",
       " 'glauce': 85345,\n",
       " 'aphrodite': 19902,\n",
       " 'bfs': 29264,\n",
       " 'atacadas': 23733,\n",
       " 'contrair': 47262,\n",
       " 'ignace': 92511,\n",
       " 'exterminada': 75494,\n",
       " 'tercero': 166076,\n",
       " 'bebido': 28194,\n",
       " 'russian': 151812,\n",
       " 'tamagotchi': 164323,\n",
       " 'personificações': 131969,\n",
       " 'rodeiam': 150542,\n",
       " 'meribá': 114609,\n",
       " 'neal': 120756,\n",
       " 'judo': 101766,\n",
       " 'счастлив': 183146,\n",
       " 'franceli': 81110,\n",
       " 'encomenda1993': 67073,\n",
       " 'ort': 126243,\n",
       " 'prédefinida': 139987,\n",
       " 'escultora': 70754,\n",
       " 'sucateado': 161908,\n",
       " 'tenro': 165858,\n",
       " 'coches': 42018,\n",
       " 'fatma': 76989,\n",
       " 'reformadores': 145581,\n",
       " 'altivez': 16330,\n",
       " 'inclina': 94504,\n",
       " 'internacionalista': 97939,\n",
       " 'cudar': 50600,\n",
       " 'feridoentre': 77783,\n",
       " 'orense': 125854,\n",
       " 'metternich': 115086,\n",
       " 'принципиально': 182779,\n",
       " 'deslfiladeiro': 57324,\n",
       " 'atletico': 24168,\n",
       " 'scriptwriter': 154470,\n",
       " 'pastora': 129385,\n",
       " 'automat': 25192,\n",
       " 'paranasais': 128425,\n",
       " 'encore': 67183,\n",
       " 'européia': 73752,\n",
       " 'abandonados': 9521,\n",
       " 'zanga': 179875,\n",
       " '884': 8508,\n",
       " 'minded': 115891,\n",
       " 'estimável': 72743,\n",
       " 'urbes': 172853,\n",
       " 'higienistas': 89932,\n",
       " '21337063': 3538,\n",
       " 'malhas': 110526,\n",
       " 'descumprir': 56333,\n",
       " 'fraccionamiento': 80992,\n",
       " 'impiedosa': 93540,\n",
       " 'zuados': 180387,\n",
       " 'esmeradamente': 71119,\n",
       " 'faille': 76190,\n",
       " '2264': 3767,\n",
       " 'fôrça': 82824,\n",
       " 'ippon': 99059,\n",
       " 'falhos': 76385,\n",
       " 'respirando': 148215,\n",
       " 'spin': 160354,\n",
       " 'latest': 105052,\n",
       " 'castelli': 37070,\n",
       " 'revertê': 149305,\n",
       " 'mamão': 110761,\n",
       " 'subestime': 161433,\n",
       " 'colhendo': 42573,\n",
       " 's8': 152095,\n",
       " 'solenidades': 159275,\n",
       " 'reformemos': 145598,\n",
       " 'topics': 168102,\n",
       " 'sachs': 152343,\n",
       " 'metalsmith': 114896,\n",
       " 'let': 106136,\n",
       " 'glock': 85464,\n",
       " 'statuo': 160763,\n",
       " 'sílfide': 163761,\n",
       " 'américas': 17613,\n",
       " 'reforma21': 145573,\n",
       " 'homologadas': 90754,\n",
       " 'etelvina': 73434,\n",
       " 'makaracorn': 110337,\n",
       " 'comparación': 43610,\n",
       " 'irrestrito': 99363,\n",
       " 'portinho': 135442,\n",
       " 'rivian': 150268,\n",
       " 'worshipful': 178845,\n",
       " 'soltinhas': 159438,\n",
       " 'lobélia': 107865,\n",
       " 'lúcia': 109426,\n",
       " 'desembarcou': 56482,\n",
       " '23h10': 3991,\n",
       " 'gritodosexcluidos': 86936,\n",
       " 'cover': 49195,\n",
       " 'carroceiros': 36633,\n",
       " '1548812168503977': 1863,\n",
       " 'distribuem': 61239,\n",
       " 'arrasava': 22001,\n",
       " 'pedalinho': 130160,\n",
       " 'scientific': 154359,\n",
       " 'impermeável': 93500,\n",
       " 'oprimidas': 125591,\n",
       " 'aulão': 24833,\n",
       " 'gagattr': 82984,\n",
       " 'censurável': 38303,\n",
       " 'retiraria': 148810,\n",
       " 'mclean': 113359,\n",
       " 'ambientação': 17006,\n",
       " 'pagnossim': 127395,\n",
       " 'clonazepan': 41597,\n",
       " 'absoluta': 10288,\n",
       " 'conspirador': 46340,\n",
       " 'cabeludo': 33717,\n",
       " 'faz': 77161,\n",
       " 'tranças': 169586,\n",
       " 'amamos': 16712,\n",
       " 'soaresoficial': 158642,\n",
       " 'odeon': 124245,\n",
       " 'ieclb': 92399,\n",
       " 'multicolores': 118882,\n",
       " 'incluyendo': 94569,\n",
       " 'xid': 179147,\n",
       " 'sidnéia': 157185,\n",
       " 'dessalinização': 58157,\n",
       " 'manezinho': 110981,\n",
       " 'impeçam': 93534,\n",
       " 'enfiado': 67584,\n",
       " 'incorruptíveis': 94830,\n",
       " 'tomaba': 167856,\n",
       " '79865': 8167,\n",
       " 'palhacinhos': 127692,\n",
       " 'brincadeiras16h': 32354,\n",
       " 'magnólias': 110056,\n",
       " 'maturéia': 112992,\n",
       " 'kula': 103901,\n",
       " 'confined': 45356,\n",
       " 'bilac': 29586,\n",
       " 'prosperou': 139417,\n",
       " 'novoprojetoperse': 122856,\n",
       " 'irresistíveis': 99345,\n",
       " 'pavimentações': 129849,\n",
       " 'newsweek': 121619,\n",
       " 'carrinho': 36625,\n",
       " '24632': 4109,\n",
       " 'nelinho': 121131,\n",
       " 'vygotsky': 177565,\n",
       " 'intrínsecas': 98443,\n",
       " 'martuscelli': 112376,\n",
       " 'tamboatá': 164361,\n",
       " 'ciniciato': 40620,\n",
       " '849': 8393,\n",
       " 'gramsci': 86404,\n",
       " 'percursão': 131105,\n",
       " 'adéquam': 13020,\n",
       " '22h30': 3821,\n",
       " 'farmácia': 76800,\n",
       " 'eclesiológica': 63862,\n",
       " 'lovecchio': 108515,\n",
       " 'novísimas': 122867,\n",
       " 'fumpac': 82176,\n",
       " '171812': 2233,\n",
       " 'ameaçamos': 17080,\n",
       " 'pioneira': 133252,\n",
       " 'scanavaca': 154083,\n",
       " 'modernizaram': 116935,\n",
       " 'antistião': 19042,\n",
       " 'sertanejos': 156204,\n",
       " 'zahm': 179815,\n",
       " 'tumulto': 171059,\n",
       " 'tight': 167113,\n",
       " 'afrodisíaco': 13592,\n",
       " 'artéria': 22655,\n",
       " 'papaleguas': 128076,\n",
       " 'rotulazinha': 151269,\n",
       " 'viggiano': 175836,\n",
       " 'chifres': 39686,\n",
       " 'antirrecessiva': 19022,\n",
       " 'convergem': 47648,\n",
       " 'ashcroft': 22850,\n",
       " 'christmases': 40043,\n",
       " 'traslade': 169658,\n",
       " 'anárquicas': 19340,\n",
       " 'ilusionismo': 92903,\n",
       " 'gemem': 84050,\n",
       " 'ajoelhava': 14636,\n",
       " 'despreze': 58041,\n",
       " 'estilosinhas': 72680,\n",
       " 'novaszonas': 122780,\n",
       " 'movilizar': 118474,\n",
       " 'gelair': 84002,\n",
       " 'celeumas': 38165,\n",
       " 'desembaraçar': 56466,\n",
       " 'funsch': 82413,\n",
       " 'monday': 117295,\n",
       " 'warming': 177934,\n",
       " 'compradores': 44058,\n",
       " 'transferidos': 169192,\n",
       " 'tâmara': 171495,\n",
       " 'ouvice': 126833,\n",
       " 'semo': 155449,\n",
       " 'contrabaixo': 47163,\n",
       " 'eiiii': 64698,\n",
       " '2061': 3342,\n",
       " '1h11min': 2903,\n",
       " 'enunciado': 69037,\n",
       " 'desarticulações': 55568,\n",
       " '529': 7143,\n",
       " 'daoud': 52249,\n",
       " 'pigmentadas': 132965,\n",
       " 'achamo': 11110,\n",
       " 'infinitivo': 95831,\n",
       " 'bukura': 32978,\n",
       " 'mancham': 110815,\n",
       " 'ним': 182351,\n",
       " 'pues': 140494,\n",
       " 'tarumã': 164755,\n",
       " 'quadros': 141380,\n",
       " 'celebrem': 38126,\n",
       " 'aaaaaaaajp8': 9369,\n",
       " 'provocava': 139864,\n",
       " 'harmonious': 88542,\n",
       " 'imensas': 93151,\n",
       " 'amortecimentos': 17425,\n",
       " 'opal': 125360,\n",
       " 'zapeando': 179915,\n",
       " 'acidentalmente': 11212,\n",
       " 'formatei': 80431,\n",
       " 'cenário': 38416,\n",
       " 'allfacebook': 15918,\n",
       " 'radiante': 142535,\n",
       " 'certinhas': 38628,\n",
       " 'sito': 158202,\n",
       " 'legitimo': 105647,\n",
       " 'indene': 95050,\n",
       " 'adversas': 12931,\n",
       " 'dunno': 63193,\n",
       " '12pensamento': 1350,\n",
       " 'ypiranga': 179662,\n",
       " 'desarticulação': 55567,\n",
       " '8800gt': 8489,\n",
       " 'contracto': 47202,\n",
       " 'vamps': 173881,\n",
       " 'desmaiada': 57401,\n",
       " 'gmac': 85561,\n",
       " 'atacaram': 23747,\n",
       " 'delicie': 53975,\n",
       " 'canaletas': 35098,\n",
       " 'useiro': 173077,\n",
       " 'jeitinhos': 100752,\n",
       " 'directly': 60287,\n",
       " 'ocampo': 123978,\n",
       " 'desconectar': 56042,\n",
       " 'имеются': 181885,\n",
       " 'wj': 178682,\n",
       " 'macroeconomia': 109722,\n",
       " 'boileau': 30792,\n",
       " 'lance': 104645,\n",
       " 'mills': 115762,\n",
       " 'mangini': 111010,\n",
       " 'soule': 160051,\n",
       " 'subúrbio': 161900,\n",
       " 'delly': 54075,\n",
       " 'nobresa': 122187,\n",
       " 'heterossexual': 89668,\n",
       " 'descendência': 55877,\n",
       " 'hangloose_procontest_86': 88404,\n",
       " 'contraface': 47238,\n",
       " 'farriáno': 76832,\n",
       " 'sonhara': 159664,\n",
       " 'jordania': 101370,\n",
       " 'malungos': 110653,\n",
       " 'rezava': 149626,\n",
       " 'groom': 86961,\n",
       " 'maloqueiro': 110591,\n",
       " 'pupilas': 140732,\n",
       " 'uso': 173115,\n",
       " 'ara': 21019,\n",
       " 'extraviaram': 75703,\n",
       " 'derrotara': 55088,\n",
       " 'hegels': 89012,\n",
       " 'boutiques': 31593,\n",
       " 'muscletone': 119282,\n",
       " 'contatocom': 46846,\n",
       " 'akihiko': 14775,\n",
       " 'encaminhá': 66758,\n",
       " 'mercenária': 114480,\n",
       " 'modafinil': 116851,\n",
       " 'trezeguet': 170048,\n",
       " 'tocarematira': 167662,\n",
       " 'apegos': 19731,\n",
       " 'bacaxá': 26325,\n",
       " 'interpõe': 98065,\n",
       " 'fcc': 77249,\n",
       " 'той': 183195,\n",
       " 'alwes': 16533,\n",
       " 'atomica': 24208,\n",
       " 'kurushimeru': 103964,\n",
       " 'biológia': 29815,\n",
       " 'serjão': 156120,\n",
       " 'universidades': 172614,\n",
       " 'bicha': 29410,\n",
       " 'island': 99562,\n",
       " 'battery': 27923,\n",
       " 'llhoa': 107792,\n",
       " 'indicada': 95160,\n",
       " 'palavraou': 127586,\n",
       " 'alecrins': 15219,\n",
       " 'despóticos': 58086,\n",
       " '1º': 3003,\n",
       " 'contagiemos': 46783,\n",
       " 'curamqualquer': 51021,\n",
       " 'trombudo': 170556,\n",
       " '2509': 4185,\n",
       " 'posicionam': 135558,\n",
       " 'consignações': 46233,\n",
       " 'restante': 148500,\n",
       " 'estimativas': 72704,\n",
       " 'astrofísicas': 23642,\n",
       " 'campanha': 34956,\n",
       " 'desandando': 55403,\n",
       " 'philosophorum': 132627,\n",
       " 'micologia': 115294,\n",
       " 'bjornstjern': 30142,\n",
       " 'rendo': 147019,\n",
       " 'tanatau': 164445,\n",
       " 'willian': 178517,\n",
       " 'inqueitude': 96628,\n",
       " 'coq': 48109,\n",
       " 'crina': 49877,\n",
       " 'inocentando': 96537,\n",
       " 'maia4': 110151,\n",
       " 'estimada': 72690,\n",
       " 'draws': 62762,\n",
       " 'refrescar': 145663,\n",
       " 'երգով': 183423,\n",
       " 'compreensão': 44129,\n",
       " '48253': 6818,\n",
       " 'enfeitavam': 67546,\n",
       " 'injuriosamente': 96459,\n",
       " 'ataides': 23769,\n",
       " 'hidrofílicas': 89811,\n",
       " 'dou': 62518,\n",
       " 'faxineira': 77152,\n",
       " 'her2': 89357,\n",
       " 'flamarion': 79322,\n",
       " 'loenquanto': 107992,\n",
       " 'extração': 75709,\n",
       " 'zovirax': 180367,\n",
       " 'veza': 175397,\n",
       " 'perscrutar': 131825,\n",
       " 'disponibilidade': 60849,\n",
       " 'принять': 182782,\n",
       " 'conscientizados': 45972,\n",
       " 'pretensamente': 137560,\n",
       " 'paí': 129923,\n",
       " 'sinapir': 157752,\n",
       " 'turbinou': 171160,\n",
       " '1dquissamã': 2877,\n",
       " 'usuras': 173161,\n",
       " 'totaliza': 168487,\n",
       " 'fichários': 78263,\n",
       " 'desabotoas': 55181,\n",
       " 'extermínios': 75515,\n",
       " 'koreatênis': 103681,\n",
       " 'mzube': 119558,\n",
       " 'xq13': 179269,\n",
       " 'koike': 103577,\n",
       " 'walters': 177859,\n",
       " 'sodio': 159061,\n",
       " 'prismas': 138000,\n",
       " 'tristedescrente': 170371,\n",
       " 'proximal': 139899,\n",
       " 'iemenitas': 92415,\n",
       " 'italki': 99768,\n",
       " 'néscio': 123350,\n",
       " 'ilidade': 92780,\n",
       " 'radiofônicos': 142602,\n",
       " 'repreendia': 147504,\n",
       " 'karma': 102658,\n",
       " 'inesgotáveis': 95578,\n",
       " 'rabin': 142386,\n",
       " 'santinha': 153412,\n",
       " 'dramatúrgicos': 62735,\n",
       " 'describes': 56254,\n",
       " 'irrecorrível': 99281,\n",
       " 'tails': 164149,\n",
       " '1634723400138069': 2048,\n",
       " 'domingues': 62189,\n",
       " 'protagonismos': 139484,\n",
       " 'fac754': 75955,\n",
       " 'finaltodos': 78728,\n",
       " 'gramophonica': 86391,\n",
       " 'seqüelas': 155962,\n",
       " 'vooooltando': 177284,\n",
       " 'pormenores': 135289,\n",
       " 'neologia': 121238,\n",
       " 'ipods': 99048,\n",
       " 'importados': 93700,\n",
       " 'desenvolvam': 56727,\n",
       " 'bordini': 31296,\n",
       " 'desfie': 56964,\n",
       " 'intermediações': 97906,\n",
       " '2987': 4907,\n",
       " 'realizava': 143661,\n",
       " 'disciplinada': 60461,\n",
       " '4000': 6457,\n",
       " 'salvia': 153012,\n",
       " 'consumar': 46668,\n",
       " 'crisma': 49927,\n",
       " 'testificando': 166462,\n",
       " '3720': 6154,\n",
       " 'smartcaps': 158487,\n",
       " 'trata': 169677,\n",
       " 'mantilla': 111302,\n",
       " 'culturaem': 50828,\n",
       " 'cortou': 48811,\n",
       " 'pesqueiro': 132245,\n",
       " '9949': 9004,\n",
       " 'lalado': 104462,\n",
       " 'ota': 126546,\n",
       " 'bd': 28054,\n",
       " 'inox': 96609,\n",
       " 'moigno': 117070,\n",
       " 'husitas': 91598,\n",
       " 'desmotivou': 57561,\n",
       " 'crac': 49329,\n",
       " 'atiçadas': 24140,\n",
       " 'divinopólis': 61514,\n",
       " 'dorama': 62359,\n",
       " 'puisqu': 140532,\n",
       " 'escribas': 70654,\n",
       " 'numerários': 123070,\n",
       " 'janeirocoff': 100411,\n",
       " 'flagstad': 79316,\n",
       " 'dâmocles': 63482,\n",
       " 'lhesevícias': 106474,\n",
       " 'mantiene': 111299,\n",
       " 'convinced': 47789,\n",
       " 'gamu': 83310,\n",
       " 'repudiar': 147721,\n",
       " 'prometo': 138951,\n",
       " 'abordá': 9973,\n",
       " 'falhado': 76366,\n",
       " 'pesticida': 132336,\n",
       " 'reconvocação': 144675,\n",
       " 'criticism': 50071,\n",
       " 'bezet': 29254,\n",
       " 'sonhavas': 159677,\n",
       " 'saneti': 153244,\n",
       " 'abonada': 9939,\n",
       " '15por': 1974,\n",
       " 'violões': 176221,\n",
       " 'aloprado': 16134,\n",
       " 'mixsem': 116636,\n",
       " 'contradições': 47235,\n",
       " 'pisco': 133481,\n",
       " '4595887': 6720,\n",
       " 'demoro': 54395,\n",
       " 'positivados': 135585,\n",
       " 'levantai': 106270,\n",
       " '4ºc': 7001,\n",
       " 'раз': 182861,\n",
       " 'desprendida': 57993,\n",
       " 'numeroso': 123065,\n",
       " 'recomeçarem': 144459,\n",
       " 'removida': 146892,\n",
       " 'neuropsicomotor': 121489,\n",
       " 'autorizando': 25319,\n",
       " 'speck': 160264,\n",
       " 'cofesa': 42179,\n",
       " 'aqui01': 20937,\n",
       " 'seresta': 156044,\n",
       " '1782': 2317,\n",
       " 'vampiro': 173878,\n",
       " 'enjoa': 68048,\n",
       " 'barcosnaveguema': 27345,\n",
       " 'misericordiosos': 116372,\n",
       " 'seventeenth': 156460,\n",
       " 'vacinadas': 173415,\n",
       " '23jesus': 4003,\n",
       " 'notoriamente': 122710,\n",
       " 'tragi': 168851,\n",
       " 'saliência': 152841,\n",
       " 'buyeong': 33367,\n",
       " 'fechadura': 77326,\n",
       " 'comboios': 43064,\n",
       " 'a2ncias': 9297,\n",
       " 'grupoehcomunicacao': 87093,\n",
       " 'fornecidos': 80550,\n",
       " 'pilhada': 133004,\n",
       " 'bagagens': 26479,\n",
       " 'bonachão': 31025,\n",
       " 'élcio': 180819,\n",
       " 'águas': 180593,\n",
       " 'nyp': 123213,\n",
       " 'wwwvalor': 178963,\n",
       " 'denominarmos': 54517,\n",
       " 'raddato': 142519,\n",
       " 'mensuravelmente': 114337,\n",
       " 'impediu': 93403,\n",
       " 'semita': 155432,\n",
       " 'alemanha471': 15334,\n",
       " 'emanoel': 65590,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vect.idf_\n",
    "vect.vocabulary_\n",
    "#vect.idf_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Models.functions.transform import tokenizer_pad_sequence\n",
    "from Models.functions.vectors import create_embeddings, train_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading embeddings...\n",
      "Vocab keys 881057\n",
      "Found 881057 word vectors.\n",
      "weights 150000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a43a7f6b7ca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "_, _, _, vect = tokenizer_pad_sequence(X, int(mean_length), params['max_num_words'])\n",
    "\n",
    "vectors_filename = r'/home/rafael/GDrive/Embeddings/word2vec/'+ dataset_name +'_sg_'+ str(params['embedding_dim']) +'dim.model'        \n",
    "embedding_type = 1\n",
    "embedding_matrix = create_embeddings(vect, params['max_num_words'], params['max_seq_length'], name=dataset_name, embedding_dim=params['embedding_dim'], filename=vectors_filename, type=embedding_type, return_matrix=True)\n",
    "\n",
    "\n",
    "corpus = []\n",
    "for instance in X_train:\n",
    "    i = []\n",
    "    for x in instance.split(\" \"):\n",
    "        i.append(x if embedding_matrix[x] else np.zeros(params['embedding_dim']))\n",
    "    corpus.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfs = pd.DataFrame()\n",
    "\n",
    "labels = np.unique(y)\n",
    "\n",
    "for label in labels:\n",
    "    pass\n",
    "\n",
    "ids = np.where(y==label)[0]\n",
    "vect = TfidfVectorizer(max_df=0.85, max_features=None, ngram_range=(1,1), analyzer='word').fit(X[ids])\n",
    "keys = list(vect.vocabulary_.keys())\n",
    "\n",
    "#idf\n",
    "#feats_df = vect.vo\n",
    "#feats_df.label = label\n",
    "\n",
    "#dfs.append(feats_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.189242  , 1.19388238, 1.25625271, 1.28640575, 1.29152085,\n",
       "       1.29666225, 1.29666225, 1.31224698, 1.31749634, 1.32807844])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(vect.idf_, kind='heapsort')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tfidf_classfeats_h(dfs):\n",
    "    ''' Plot the data frames returned by the function plot_tfidf_classfeats(). '''\n",
    "    fig = plt.figure(figsize=(12, 9), facecolor=\"w\")\n",
    "    x = np.arange(len(dfs[0]))\n",
    "    for i, df in enumerate(dfs):\n",
    "        ax = fig.add_subplot(1, len(dfs), i+1)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.set_frame_on(False)\n",
    "        ax.get_xaxis().tick_bottom()\n",
    "        ax.get_yaxis().tick_left()\n",
    "        ax.set_xlabel(\"Mean Tf-Idf Score\", labelpad=16, fontsize=14)\n",
    "        ax.set_title(\"label = \" + str(df.label), fontsize=16)\n",
    "        ax.ticklabel_format(axis='x', style='sci', scilimits=(-2,2))\n",
    "        ax.barh(x, df.tfidf, align='center', color='#3F5D7D')\n",
    "        ax.set_yticks(x)\n",
    "        ax.set_ylim([-1, x[-1]+1])\n",
    "        yticks = ax.set_yticklabels(df.feature)\n",
    "        plt.subplots_adjust(bottom=0.09, right=0.97, left=0.15, top=0.95, wspace=0.52)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hipothesis\n",
    "\n",
    "- Feature selection\n",
    "\n",
    "I was a bit result improvements, from 0.37 to 0.41 f1score.\n",
    "\n",
    "The second step maybe try to test with CNN and RNN\n",
    "\n",
    "- One vs Rest\n",
    "\n",
    "Understand more how i can do this.\n",
    "\n",
    "Model for one label vs rest of labels seems that dont work\n",
    "\n",
    "Maybe using oversampling/undersampling\n",
    "\n",
    "\n",
    "- Anything more?\n",
    "\n",
    "using the mean word embedding with simple CNN to try and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
