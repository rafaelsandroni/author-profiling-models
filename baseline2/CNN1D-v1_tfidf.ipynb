{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.functions.plot import plot_history, full_multiclass_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Input, Dense, Flatten, Dropout, Embedding\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "#from Models.functions.preprocessing import clean\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import pandas as pd\n",
    "result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(filters = [100], kernel_size = [50], strides = [100], \n",
    "                 dropout_rate = [0.5], pool_size = [5], max_len = 1000):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # conv 1\n",
    "    model.add(Conv1D(filters = filters[0], \n",
    "                     kernel_size = kernel_size[0],\n",
    "                     strides = strides[0], \n",
    "                     activation = 'relu', \n",
    "                     input_shape = (max_len, 1) ))\n",
    "\n",
    "    # pooling layer 1\n",
    "    model.add(MaxPooling1D(pool_size = pool_size[0], strides = 1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 100, activation = 'relu'))\n",
    "    model.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "    model.compile(optimizer = 'adadelta', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_results(model, y_espected, y_predicted):\n",
    "\n",
    "    config = model.get_config()\n",
    "\n",
    "    row = {}\n",
    "\n",
    "    conv_layers = np.sum([1 if i['class_name'] == \"Conv1D\" else 0 for i in config])\n",
    "    pooling_layers = np.sum([1 if i['class_name'] == \"MaxPooling1D\" else 0 for i in config])\n",
    "\n",
    "    row.update({ '_accuracy': accuracy_score(y_espected, y_predicted) })\n",
    "    row.update({ '_f1-score': f1_score(y_espected, y_predicted,average='weighted')})\n",
    "    row.update({ 'conv_layers': conv_layers })\n",
    "    row.update({ 'pooling_layers': pooling_layers })\n",
    "\n",
    "    _, _, fscore, support = precision_recall_fscore_support(y_espected, y_predicted)\n",
    "\n",
    "    [row.update({'_fscore_class_'+str(i[0]): i[1]}) for i in enumerate(fscore)]\n",
    "    [row.update({'_support_class_'+str(i[0]): i[1]}) for i in enumerate(support)]\n",
    "\n",
    "    idx = 1\n",
    "    for i in config:\n",
    "        if i['class_name'] == \"Conv1D\":\n",
    "            j = str(idx)\n",
    "            row.update({\n",
    "                'filters_'+j: i['config']['filters'],\n",
    "                'strides_'+j: i['config']['strides'],\n",
    "                'kernel_size_'+j: i['config']['kernel_size'],\n",
    "                'activation_'+j: i['config']['activation']\n",
    "            })\n",
    "        pass\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoder(y):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y)\n",
    "    return (le.transform(y), len(le.classes_), list(le.classes_))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2602,), (2081,), (521,))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Models.functions.datasets import loadTrainTest\n",
    "X_train, X_test, y_train, y_test = loadTrainTest(\"gender\", \"brblogset\", \"/home/rafael/GDrive/Data/Dataframe/\")\n",
    "\n",
    "y_train, n, _ = labelEncoder(y_train)\n",
    "y_test, n, classes_names = labelEncoder(y_test)\n",
    "\n",
    "X = np.concatenate([X_train, X_test])\n",
    "\n",
    "vect = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "vect.fit(X)\n",
    "\n",
    "X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2081, 1000), (521, 1000))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf = vect.transform(X_train).toarray()\n",
    "X_test_tfidf = vect.transform(X_test).toarray()\n",
    "\n",
    "X_train_tfidf.shape, X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599293 5537.368572801538 2423.0 2423 False\n"
     ]
    }
   ],
   "source": [
    "max_length = np.max([len(x.split(\" \")) for x in X_train])\n",
    "mean_length = np.mean([len(x.split(\" \")) for x in X_train])\n",
    "mediam_length = np.median([len(x.split(\" \")) for x in X_train])\n",
    "\n",
    "print(max_length, mean_length, mediam_length, int(mediam_length), int(mediam_length) == 2255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 840, 1: 1241}), Counter({0: 1241, 1: 1241}))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import collections, numpy\n",
    "\n",
    "# Synthetic Minority Oversampling Technique (SMOTE)\n",
    "def oversampling(X, y):\n",
    "    X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "X_resampled, y_resampled = oversampling(X_train_tfidf, y_train)\n",
    "\n",
    "#scaler = StandardScaler().fit(X)\n",
    "#m = scaler.transform(X)\n",
    "#m = matrix2\n",
    "\n",
    "collections.Counter(y_train), collections.Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1985, 1000) (497, 1000) (1985,) (497,)\n",
      "1985 1985\n",
      "497 497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((497, 1000, 1), (1000, 1))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = 0.2)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "#y_train = to_categorical(y_train, 2)\n",
    "#y_test = to_categorical(y_test, 2)\n",
    "print(len(y_train), len(x_train))\n",
    "print(len(y_test), len(x_test))\n",
    "#print()\n",
    "#print(y_test)\n",
    "\n",
    "x_test.shape, x_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa7a77b24a8>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7b12f0f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "xid, yid = 10, 222\n",
    "plt.scatter(x_train[:,xid], x_train[:,yid],c=y_train)\n",
    "#plt.ylabel(classes_names[0])\n",
    "#plt.ylabel(classes_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "done in 5931.95s and 98.9min\n",
      "\n",
      "Best parameters set:\n",
      "\tdropout_rate: [0.5]\n",
      "\tepochs: 100\n",
      "\tfilters: [50]\n",
      "\tkernel_size: [50]\n",
      "\tpool_size: [15]\n",
      "\tstrides: [5]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_dropout_rate</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_filters</th>\n",
       "      <th>param_kernel_size</th>\n",
       "      <th>param_pool_size</th>\n",
       "      <th>param_strides</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.373501</td>\n",
       "      <td>0.368067</td>\n",
       "      <td>0.702771</td>\n",
       "      <td>0.870278</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694864</td>\n",
       "      <td>0.840514</td>\n",
       "      <td>0.731118</td>\n",
       "      <td>0.905518</td>\n",
       "      <td>0.682300</td>\n",
       "      <td>0.864804</td>\n",
       "      <td>0.144459</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>0.026819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.403984</td>\n",
       "      <td>0.373201</td>\n",
       "      <td>0.703275</td>\n",
       "      <td>0.890428</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709970</td>\n",
       "      <td>0.907785</td>\n",
       "      <td>0.711480</td>\n",
       "      <td>0.872260</td>\n",
       "      <td>0.688351</td>\n",
       "      <td>0.891239</td>\n",
       "      <td>0.063238</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.014514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.649614</td>\n",
       "      <td>0.366145</td>\n",
       "      <td>0.700756</td>\n",
       "      <td>0.807297</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703927</td>\n",
       "      <td>0.783069</td>\n",
       "      <td>0.719033</td>\n",
       "      <td>0.801209</td>\n",
       "      <td>0.679274</td>\n",
       "      <td>0.837613</td>\n",
       "      <td>0.067283</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.016384</td>\n",
       "      <td>0.022680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.506116</td>\n",
       "      <td>0.447054</td>\n",
       "      <td>0.697733</td>\n",
       "      <td>0.876572</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690332</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.723565</td>\n",
       "      <td>0.897203</td>\n",
       "      <td>0.679274</td>\n",
       "      <td>0.886707</td>\n",
       "      <td>0.158460</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.018822</td>\n",
       "      <td>0.022173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.776733</td>\n",
       "      <td>0.464497</td>\n",
       "      <td>0.670025</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688822</td>\n",
       "      <td>0.885865</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.876039</td>\n",
       "      <td>0.623298</td>\n",
       "      <td>0.728097</td>\n",
       "      <td>0.040626</td>\n",
       "      <td>0.016844</td>\n",
       "      <td>0.033223</td>\n",
       "      <td>0.072168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.514287</td>\n",
       "      <td>0.457508</td>\n",
       "      <td>0.658942</td>\n",
       "      <td>0.711589</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688822</td>\n",
       "      <td>0.755858</td>\n",
       "      <td>0.628399</td>\n",
       "      <td>0.674981</td>\n",
       "      <td>0.659607</td>\n",
       "      <td>0.703927</td>\n",
       "      <td>0.131727</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.024678</td>\n",
       "      <td>0.033459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.158983</td>\n",
       "      <td>0.543776</td>\n",
       "      <td>0.729975</td>\n",
       "      <td>0.924435</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740181</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.738671</td>\n",
       "      <td>0.934996</td>\n",
       "      <td>0.711044</td>\n",
       "      <td>0.917674</td>\n",
       "      <td>0.184444</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.013390</td>\n",
       "      <td>0.007565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.952710</td>\n",
       "      <td>0.548508</td>\n",
       "      <td>0.691184</td>\n",
       "      <td>0.886902</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672205</td>\n",
       "      <td>0.896447</td>\n",
       "      <td>0.696375</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.704992</td>\n",
       "      <td>0.886707</td>\n",
       "      <td>0.055997</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>0.013878</td>\n",
       "      <td>0.007716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.808253</td>\n",
       "      <td>0.537318</td>\n",
       "      <td>0.721914</td>\n",
       "      <td>0.880352</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728097</td>\n",
       "      <td>0.897203</td>\n",
       "      <td>0.729607</td>\n",
       "      <td>0.860922</td>\n",
       "      <td>0.708018</td>\n",
       "      <td>0.882931</td>\n",
       "      <td>0.068562</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.009838</td>\n",
       "      <td>0.014924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.286860</td>\n",
       "      <td>0.632781</td>\n",
       "      <td>0.720907</td>\n",
       "      <td>0.887900</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717523</td>\n",
       "      <td>0.872260</td>\n",
       "      <td>0.702417</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.742814</td>\n",
       "      <td>0.922961</td>\n",
       "      <td>0.146532</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>0.024839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.280829</td>\n",
       "      <td>0.644304</td>\n",
       "      <td>0.684131</td>\n",
       "      <td>0.884144</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738671</td>\n",
       "      <td>0.934996</td>\n",
       "      <td>0.649547</td>\n",
       "      <td>0.883598</td>\n",
       "      <td>0.664145</td>\n",
       "      <td>0.833837</td>\n",
       "      <td>0.036340</td>\n",
       "      <td>0.014131</td>\n",
       "      <td>0.039037</td>\n",
       "      <td>0.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.688149</td>\n",
       "      <td>0.630575</td>\n",
       "      <td>0.675567</td>\n",
       "      <td>0.759188</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.779289</td>\n",
       "      <td>0.655589</td>\n",
       "      <td>0.716553</td>\n",
       "      <td>0.673222</td>\n",
       "      <td>0.781722</td>\n",
       "      <td>0.073570</td>\n",
       "      <td>0.014211</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>0.030164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>58.260213</td>\n",
       "      <td>0.762892</td>\n",
       "      <td>0.713854</td>\n",
       "      <td>0.897730</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737160</td>\n",
       "      <td>0.867725</td>\n",
       "      <td>0.708459</td>\n",
       "      <td>0.916100</td>\n",
       "      <td>0.695915</td>\n",
       "      <td>0.909366</td>\n",
       "      <td>0.280576</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.017263</td>\n",
       "      <td>0.021394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29.259355</td>\n",
       "      <td>0.748174</td>\n",
       "      <td>0.715869</td>\n",
       "      <td>0.877578</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722054</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.708459</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.717095</td>\n",
       "      <td>0.893505</td>\n",
       "      <td>0.281599</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.025738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.693143</td>\n",
       "      <td>0.729755</td>\n",
       "      <td>0.670529</td>\n",
       "      <td>0.767737</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626888</td>\n",
       "      <td>0.675737</td>\n",
       "      <td>0.679758</td>\n",
       "      <td>0.776266</td>\n",
       "      <td>0.704992</td>\n",
       "      <td>0.851208</td>\n",
       "      <td>0.087334</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.032543</td>\n",
       "      <td>0.071889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>57.893832</td>\n",
       "      <td>0.852559</td>\n",
       "      <td>0.654912</td>\n",
       "      <td>0.803248</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626888</td>\n",
       "      <td>0.704460</td>\n",
       "      <td>0.638973</td>\n",
       "      <td>0.795163</td>\n",
       "      <td>0.698941</td>\n",
       "      <td>0.910121</td>\n",
       "      <td>0.208802</td>\n",
       "      <td>0.008422</td>\n",
       "      <td>0.031499</td>\n",
       "      <td>0.084155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28.870825</td>\n",
       "      <td>0.835932</td>\n",
       "      <td>0.633249</td>\n",
       "      <td>0.767991</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625378</td>\n",
       "      <td>0.722600</td>\n",
       "      <td>0.611782</td>\n",
       "      <td>0.736206</td>\n",
       "      <td>0.662632</td>\n",
       "      <td>0.845166</td>\n",
       "      <td>0.068322</td>\n",
       "      <td>0.015496</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.054853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.232352</td>\n",
       "      <td>0.808241</td>\n",
       "      <td>0.674055</td>\n",
       "      <td>0.747085</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673716</td>\n",
       "      <td>0.718065</td>\n",
       "      <td>0.641994</td>\n",
       "      <td>0.705215</td>\n",
       "      <td>0.706505</td>\n",
       "      <td>0.817976</td>\n",
       "      <td>0.092937</td>\n",
       "      <td>0.008934</td>\n",
       "      <td>0.026334</td>\n",
       "      <td>0.050401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>57.774416</td>\n",
       "      <td>0.945709</td>\n",
       "      <td>0.696222</td>\n",
       "      <td>0.843099</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719033</td>\n",
       "      <td>0.897203</td>\n",
       "      <td>0.725076</td>\n",
       "      <td>0.891912</td>\n",
       "      <td>0.644478</td>\n",
       "      <td>0.740181</td>\n",
       "      <td>0.284525</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>0.036644</td>\n",
       "      <td>0.072806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30.149072</td>\n",
       "      <td>0.930903</td>\n",
       "      <td>0.691688</td>\n",
       "      <td>0.858169</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643505</td>\n",
       "      <td>0.723356</td>\n",
       "      <td>0.717523</td>\n",
       "      <td>0.924414</td>\n",
       "      <td>0.714070</td>\n",
       "      <td>0.926737</td>\n",
       "      <td>0.252996</td>\n",
       "      <td>0.014219</td>\n",
       "      <td>0.034113</td>\n",
       "      <td>0.095332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.760205</td>\n",
       "      <td>0.920104</td>\n",
       "      <td>0.675063</td>\n",
       "      <td>0.823180</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.658610</td>\n",
       "      <td>0.801965</td>\n",
       "      <td>0.668684</td>\n",
       "      <td>0.799094</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.016659</td>\n",
       "      <td>0.032054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>57.791625</td>\n",
       "      <td>1.042208</td>\n",
       "      <td>0.669018</td>\n",
       "      <td>0.787632</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685801</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.619335</td>\n",
       "      <td>0.635676</td>\n",
       "      <td>0.701967</td>\n",
       "      <td>0.890483</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.035758</td>\n",
       "      <td>0.109666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29.529427</td>\n",
       "      <td>1.029191</td>\n",
       "      <td>0.703275</td>\n",
       "      <td>0.879593</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725076</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.654079</td>\n",
       "      <td>0.826909</td>\n",
       "      <td>0.730711</td>\n",
       "      <td>0.893505</td>\n",
       "      <td>0.027666</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>0.034876</td>\n",
       "      <td>0.038612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.490400</td>\n",
       "      <td>1.010421</td>\n",
       "      <td>0.696725</td>\n",
       "      <td>0.827206</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658610</td>\n",
       "      <td>0.787604</td>\n",
       "      <td>0.735650</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.695915</td>\n",
       "      <td>0.820997</td>\n",
       "      <td>0.111496</td>\n",
       "      <td>0.020538</td>\n",
       "      <td>0.031464</td>\n",
       "      <td>0.035145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>62.941042</td>\n",
       "      <td>1.094175</td>\n",
       "      <td>0.739043</td>\n",
       "      <td>0.938791</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744713</td>\n",
       "      <td>0.939531</td>\n",
       "      <td>0.734139</td>\n",
       "      <td>0.938020</td>\n",
       "      <td>0.738275</td>\n",
       "      <td>0.938822</td>\n",
       "      <td>0.093119</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>35.934511</td>\n",
       "      <td>1.111873</td>\n",
       "      <td>0.719395</td>\n",
       "      <td>0.934759</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706949</td>\n",
       "      <td>0.914588</td>\n",
       "      <td>0.737160</td>\n",
       "      <td>0.949358</td>\n",
       "      <td>0.714070</td>\n",
       "      <td>0.940332</td>\n",
       "      <td>0.133912</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.014731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.042928</td>\n",
       "      <td>1.096649</td>\n",
       "      <td>0.706801</td>\n",
       "      <td>0.878074</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.828420</td>\n",
       "      <td>0.705438</td>\n",
       "      <td>0.881330</td>\n",
       "      <td>0.717095</td>\n",
       "      <td>0.924471</td>\n",
       "      <td>0.333705</td>\n",
       "      <td>0.011215</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.039280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>63.523600</td>\n",
       "      <td>1.232168</td>\n",
       "      <td>0.729471</td>\n",
       "      <td>0.938540</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753776</td>\n",
       "      <td>0.937264</td>\n",
       "      <td>0.728097</td>\n",
       "      <td>0.942555</td>\n",
       "      <td>0.706505</td>\n",
       "      <td>0.935801</td>\n",
       "      <td>0.142636</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>0.019320</td>\n",
       "      <td>0.002901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>36.413423</td>\n",
       "      <td>1.223420</td>\n",
       "      <td>0.713854</td>\n",
       "      <td>0.934257</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722054</td>\n",
       "      <td>0.944822</td>\n",
       "      <td>0.712991</td>\n",
       "      <td>0.924414</td>\n",
       "      <td>0.706505</td>\n",
       "      <td>0.933535</td>\n",
       "      <td>0.114926</td>\n",
       "      <td>0.013930</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.008347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15.464315</td>\n",
       "      <td>1.219578</td>\n",
       "      <td>0.674055</td>\n",
       "      <td>0.796219</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682779</td>\n",
       "      <td>0.846561</td>\n",
       "      <td>0.637462</td>\n",
       "      <td>0.733938</td>\n",
       "      <td>0.701967</td>\n",
       "      <td>0.808157</td>\n",
       "      <td>0.127889</td>\n",
       "      <td>0.011108</td>\n",
       "      <td>0.027044</td>\n",
       "      <td>0.046747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>64.123686</td>\n",
       "      <td>1.301519</td>\n",
       "      <td>0.732494</td>\n",
       "      <td>0.943324</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740181</td>\n",
       "      <td>0.934996</td>\n",
       "      <td>0.722054</td>\n",
       "      <td>0.946334</td>\n",
       "      <td>0.735250</td>\n",
       "      <td>0.948640</td>\n",
       "      <td>0.325970</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.005963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>38.824937</td>\n",
       "      <td>1.310118</td>\n",
       "      <td>0.731486</td>\n",
       "      <td>0.943578</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735650</td>\n",
       "      <td>0.942555</td>\n",
       "      <td>0.744713</td>\n",
       "      <td>0.948602</td>\n",
       "      <td>0.714070</td>\n",
       "      <td>0.939577</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>0.003755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>18.064238</td>\n",
       "      <td>1.312206</td>\n",
       "      <td>0.718892</td>\n",
       "      <td>0.925436</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729607</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>0.690332</td>\n",
       "      <td>0.912320</td>\n",
       "      <td>0.736762</td>\n",
       "      <td>0.942598</td>\n",
       "      <td>0.108048</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>0.012688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>64.639354</td>\n",
       "      <td>1.405400</td>\n",
       "      <td>0.754156</td>\n",
       "      <td>0.942315</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761329</td>\n",
       "      <td>0.934240</td>\n",
       "      <td>0.744713</td>\n",
       "      <td>0.941799</td>\n",
       "      <td>0.756430</td>\n",
       "      <td>0.950906</td>\n",
       "      <td>0.183907</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>0.006814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>39.299264</td>\n",
       "      <td>1.406418</td>\n",
       "      <td>0.735516</td>\n",
       "      <td>0.945844</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753776</td>\n",
       "      <td>0.940287</td>\n",
       "      <td>0.720544</td>\n",
       "      <td>0.953137</td>\n",
       "      <td>0.732224</td>\n",
       "      <td>0.944109</td>\n",
       "      <td>0.126460</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>0.005387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>17.871913</td>\n",
       "      <td>1.405986</td>\n",
       "      <td>0.728967</td>\n",
       "      <td>0.935769</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719033</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.729607</td>\n",
       "      <td>0.948602</td>\n",
       "      <td>0.738275</td>\n",
       "      <td>0.932779</td>\n",
       "      <td>0.426031</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>0.009496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>118.807482</td>\n",
       "      <td>1.564465</td>\n",
       "      <td>0.730982</td>\n",
       "      <td>0.942820</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732628</td>\n",
       "      <td>0.935752</td>\n",
       "      <td>0.734139</td>\n",
       "      <td>0.945578</td>\n",
       "      <td>0.726172</td>\n",
       "      <td>0.947130</td>\n",
       "      <td>0.112370</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.005038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>62.557171</td>\n",
       "      <td>1.547379</td>\n",
       "      <td>0.732494</td>\n",
       "      <td>0.943072</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740181</td>\n",
       "      <td>0.935752</td>\n",
       "      <td>0.726586</td>\n",
       "      <td>0.947846</td>\n",
       "      <td>0.730711</td>\n",
       "      <td>0.945619</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.005255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>22.426279</td>\n",
       "      <td>1.518357</td>\n",
       "      <td>0.706297</td>\n",
       "      <td>0.896480</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731118</td>\n",
       "      <td>0.909297</td>\n",
       "      <td>0.703927</td>\n",
       "      <td>0.909297</td>\n",
       "      <td>0.683812</td>\n",
       "      <td>0.870846</td>\n",
       "      <td>0.077983</td>\n",
       "      <td>0.013173</td>\n",
       "      <td>0.019383</td>\n",
       "      <td>0.018126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>118.455265</td>\n",
       "      <td>1.656164</td>\n",
       "      <td>0.727960</td>\n",
       "      <td>0.940051</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756798</td>\n",
       "      <td>0.942555</td>\n",
       "      <td>0.725076</td>\n",
       "      <td>0.940287</td>\n",
       "      <td>0.701967</td>\n",
       "      <td>0.937311</td>\n",
       "      <td>0.161299</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>0.022475</td>\n",
       "      <td>0.002147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>61.595242</td>\n",
       "      <td>1.644034</td>\n",
       "      <td>0.711335</td>\n",
       "      <td>0.940554</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>0.731118</td>\n",
       "      <td>0.934996</td>\n",
       "      <td>0.704992</td>\n",
       "      <td>0.939577</td>\n",
       "      <td>0.250601</td>\n",
       "      <td>0.006809</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.004985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>21.154323</td>\n",
       "      <td>1.615296</td>\n",
       "      <td>0.674559</td>\n",
       "      <td>0.823407</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661631</td>\n",
       "      <td>0.768707</td>\n",
       "      <td>0.654079</td>\n",
       "      <td>0.803477</td>\n",
       "      <td>0.708018</td>\n",
       "      <td>0.898036</td>\n",
       "      <td>0.089953</td>\n",
       "      <td>0.025677</td>\n",
       "      <td>0.023842</td>\n",
       "      <td>0.054647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>118.751176</td>\n",
       "      <td>1.757707</td>\n",
       "      <td>0.744584</td>\n",
       "      <td>0.944835</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746224</td>\n",
       "      <td>0.937264</td>\n",
       "      <td>0.746224</td>\n",
       "      <td>0.947846</td>\n",
       "      <td>0.741301</td>\n",
       "      <td>0.949396</td>\n",
       "      <td>0.253217</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.005391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>63.619786</td>\n",
       "      <td>1.753671</td>\n",
       "      <td>0.738539</td>\n",
       "      <td>0.945088</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746224</td>\n",
       "      <td>0.951625</td>\n",
       "      <td>0.726586</td>\n",
       "      <td>0.937264</td>\n",
       "      <td>0.742814</td>\n",
       "      <td>0.946375</td>\n",
       "      <td>0.177979</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>0.005933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>24.588449</td>\n",
       "      <td>1.713988</td>\n",
       "      <td>0.731990</td>\n",
       "      <td>0.941560</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725076</td>\n",
       "      <td>0.922902</td>\n",
       "      <td>0.735650</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.735250</td>\n",
       "      <td>0.949396</td>\n",
       "      <td>0.194354</td>\n",
       "      <td>0.022493</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.013249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>118.429960</td>\n",
       "      <td>1.859683</td>\n",
       "      <td>0.740050</td>\n",
       "      <td>0.945088</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744713</td>\n",
       "      <td>0.940287</td>\n",
       "      <td>0.735650</td>\n",
       "      <td>0.948602</td>\n",
       "      <td>0.739788</td>\n",
       "      <td>0.946375</td>\n",
       "      <td>0.121901</td>\n",
       "      <td>0.009699</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.003514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>62.767895</td>\n",
       "      <td>1.850701</td>\n",
       "      <td>0.732494</td>\n",
       "      <td>0.954910</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726586</td>\n",
       "      <td>0.951625</td>\n",
       "      <td>0.743202</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.727685</td>\n",
       "      <td>0.960725</td>\n",
       "      <td>0.562426</td>\n",
       "      <td>0.020096</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.004123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>23.483309</td>\n",
       "      <td>1.840403</td>\n",
       "      <td>0.703275</td>\n",
       "      <td>0.914601</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714502</td>\n",
       "      <td>0.919879</td>\n",
       "      <td>0.667674</td>\n",
       "      <td>0.876795</td>\n",
       "      <td>0.727685</td>\n",
       "      <td>0.947130</td>\n",
       "      <td>0.115709</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>0.025752</td>\n",
       "      <td>0.028956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       29.373501         0.368067         0.702771          0.870278   \n",
       "1       15.403984         0.373201         0.703275          0.890428   \n",
       "2        5.649614         0.366145         0.700756          0.807297   \n",
       "3       29.506116         0.447054         0.697733          0.876572   \n",
       "4       15.776733         0.464497         0.670025          0.830000   \n",
       "5        5.514287         0.457508         0.658942          0.711589   \n",
       "6       30.158983         0.543776         0.729975          0.924435   \n",
       "7       16.952710         0.548508         0.691184          0.886902   \n",
       "8        6.808253         0.537318         0.721914          0.880352   \n",
       "9       30.286860         0.632781         0.720907          0.887900   \n",
       "10      17.280829         0.644304         0.684131          0.884144   \n",
       "11       6.688149         0.630575         0.675567          0.759188   \n",
       "12      58.260213         0.762892         0.713854          0.897730   \n",
       "13      29.259355         0.748174         0.715869          0.877578   \n",
       "14       8.693143         0.729755         0.670529          0.767737   \n",
       "15      57.893832         0.852559         0.654912          0.803248   \n",
       "16      28.870825         0.835932         0.633249          0.767991   \n",
       "17       8.232352         0.808241         0.674055          0.747085   \n",
       "18      57.774416         0.945709         0.696222          0.843099   \n",
       "19      30.149072         0.930903         0.691688          0.858169   \n",
       "20       9.760205         0.920104         0.675063          0.823180   \n",
       "21      57.791625         1.042208         0.669018          0.787632   \n",
       "22      29.529427         1.029191         0.703275          0.879593   \n",
       "23       9.490400         1.010421         0.696725          0.827206   \n",
       "24      62.941042         1.094175         0.739043          0.938791   \n",
       "25      35.934511         1.111873         0.719395          0.934759   \n",
       "26      16.042928         1.096649         0.706801          0.878074   \n",
       "27      63.523600         1.232168         0.729471          0.938540   \n",
       "28      36.413423         1.223420         0.713854          0.934257   \n",
       "29      15.464315         1.219578         0.674055          0.796219   \n",
       "30      64.123686         1.301519         0.732494          0.943324   \n",
       "31      38.824937         1.310118         0.731486          0.943578   \n",
       "32      18.064238         1.312206         0.718892          0.925436   \n",
       "33      64.639354         1.405400         0.754156          0.942315   \n",
       "34      39.299264         1.406418         0.735516          0.945844   \n",
       "35      17.871913         1.405986         0.728967          0.935769   \n",
       "36     118.807482         1.564465         0.730982          0.942820   \n",
       "37      62.557171         1.547379         0.732494          0.943072   \n",
       "38      22.426279         1.518357         0.706297          0.896480   \n",
       "39     118.455265         1.656164         0.727960          0.940051   \n",
       "40      61.595242         1.644034         0.711335          0.940554   \n",
       "41      21.154323         1.615296         0.674559          0.823407   \n",
       "42     118.751176         1.757707         0.744584          0.944835   \n",
       "43      63.619786         1.753671         0.738539          0.945088   \n",
       "44      24.588449         1.713988         0.731990          0.941560   \n",
       "45     118.429960         1.859683         0.740050          0.945088   \n",
       "46      62.767895         1.850701         0.732494          0.954910   \n",
       "47      23.483309         1.840403         0.703275          0.914601   \n",
       "\n",
       "   param_dropout_rate param_epochs param_filters param_kernel_size  \\\n",
       "0               [0.5]           50          [50]              [30]   \n",
       "1               [0.5]           50          [50]              [30]   \n",
       "2               [0.5]           50          [50]              [30]   \n",
       "3               [0.5]           50          [50]              [30]   \n",
       "4               [0.5]           50          [50]              [30]   \n",
       "5               [0.5]           50          [50]              [30]   \n",
       "6               [0.5]           50          [50]              [50]   \n",
       "7               [0.5]           50          [50]              [50]   \n",
       "8               [0.5]           50          [50]              [50]   \n",
       "9               [0.5]           50          [50]              [50]   \n",
       "10              [0.5]           50          [50]              [50]   \n",
       "11              [0.5]           50          [50]              [50]   \n",
       "12              [0.5]           50         [100]              [30]   \n",
       "13              [0.5]           50         [100]              [30]   \n",
       "14              [0.5]           50         [100]              [30]   \n",
       "15              [0.5]           50         [100]              [30]   \n",
       "16              [0.5]           50         [100]              [30]   \n",
       "17              [0.5]           50         [100]              [30]   \n",
       "18              [0.5]           50         [100]              [50]   \n",
       "19              [0.5]           50         [100]              [50]   \n",
       "20              [0.5]           50         [100]              [50]   \n",
       "21              [0.5]           50         [100]              [50]   \n",
       "22              [0.5]           50         [100]              [50]   \n",
       "23              [0.5]           50         [100]              [50]   \n",
       "24              [0.5]          100          [50]              [30]   \n",
       "25              [0.5]          100          [50]              [30]   \n",
       "26              [0.5]          100          [50]              [30]   \n",
       "27              [0.5]          100          [50]              [30]   \n",
       "28              [0.5]          100          [50]              [30]   \n",
       "29              [0.5]          100          [50]              [30]   \n",
       "30              [0.5]          100          [50]              [50]   \n",
       "31              [0.5]          100          [50]              [50]   \n",
       "32              [0.5]          100          [50]              [50]   \n",
       "33              [0.5]          100          [50]              [50]   \n",
       "34              [0.5]          100          [50]              [50]   \n",
       "35              [0.5]          100          [50]              [50]   \n",
       "36              [0.5]          100         [100]              [30]   \n",
       "37              [0.5]          100         [100]              [30]   \n",
       "38              [0.5]          100         [100]              [30]   \n",
       "39              [0.5]          100         [100]              [30]   \n",
       "40              [0.5]          100         [100]              [30]   \n",
       "41              [0.5]          100         [100]              [30]   \n",
       "42              [0.5]          100         [100]              [50]   \n",
       "43              [0.5]          100         [100]              [50]   \n",
       "44              [0.5]          100         [100]              [50]   \n",
       "45              [0.5]          100         [100]              [50]   \n",
       "46              [0.5]          100         [100]              [50]   \n",
       "47              [0.5]          100         [100]              [50]   \n",
       "\n",
       "   param_pool_size param_strides       ...        split0_test_score  \\\n",
       "0             [10]           [5]       ...                 0.694864   \n",
       "1             [10]          [10]       ...                 0.709970   \n",
       "2             [10]          [50]       ...                 0.703927   \n",
       "3             [15]           [5]       ...                 0.690332   \n",
       "4             [15]          [10]       ...                 0.688822   \n",
       "5             [15]          [50]       ...                 0.688822   \n",
       "6             [10]           [5]       ...                 0.740181   \n",
       "7             [10]          [10]       ...                 0.672205   \n",
       "8             [10]          [50]       ...                 0.728097   \n",
       "9             [15]           [5]       ...                 0.717523   \n",
       "10            [15]          [10]       ...                 0.738671   \n",
       "11            [15]          [50]       ...                 0.697885   \n",
       "12            [10]           [5]       ...                 0.737160   \n",
       "13            [10]          [10]       ...                 0.722054   \n",
       "14            [10]          [50]       ...                 0.626888   \n",
       "15            [15]           [5]       ...                 0.626888   \n",
       "16            [15]          [10]       ...                 0.625378   \n",
       "17            [15]          [50]       ...                 0.673716   \n",
       "18            [10]           [5]       ...                 0.719033   \n",
       "19            [10]          [10]       ...                 0.643505   \n",
       "20            [10]          [50]       ...                 0.697885   \n",
       "21            [15]           [5]       ...                 0.685801   \n",
       "22            [15]          [10]       ...                 0.725076   \n",
       "23            [15]          [50]       ...                 0.658610   \n",
       "24            [10]           [5]       ...                 0.744713   \n",
       "25            [10]          [10]       ...                 0.706949   \n",
       "26            [10]          [50]       ...                 0.697885   \n",
       "27            [15]           [5]       ...                 0.753776   \n",
       "28            [15]          [10]       ...                 0.722054   \n",
       "29            [15]          [50]       ...                 0.682779   \n",
       "30            [10]           [5]       ...                 0.740181   \n",
       "31            [10]          [10]       ...                 0.735650   \n",
       "32            [10]          [50]       ...                 0.729607   \n",
       "33            [15]           [5]       ...                 0.761329   \n",
       "34            [15]          [10]       ...                 0.753776   \n",
       "35            [15]          [50]       ...                 0.719033   \n",
       "36            [10]           [5]       ...                 0.732628   \n",
       "37            [10]          [10]       ...                 0.740181   \n",
       "38            [10]          [50]       ...                 0.731118   \n",
       "39            [15]           [5]       ...                 0.756798   \n",
       "40            [15]          [10]       ...                 0.697885   \n",
       "41            [15]          [50]       ...                 0.661631   \n",
       "42            [10]           [5]       ...                 0.746224   \n",
       "43            [10]          [10]       ...                 0.746224   \n",
       "44            [10]          [50]       ...                 0.725076   \n",
       "45            [15]           [5]       ...                 0.744713   \n",
       "46            [15]          [10]       ...                 0.726586   \n",
       "47            [15]          [50]       ...                 0.714502   \n",
       "\n",
       "    split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0             0.840514           0.731118            0.905518   \n",
       "1             0.907785           0.711480            0.872260   \n",
       "2             0.783069           0.719033            0.801209   \n",
       "3             0.845805           0.723565            0.897203   \n",
       "4             0.885865           0.697885            0.876039   \n",
       "5             0.755858           0.628399            0.674981   \n",
       "6             0.920635           0.738671            0.934996   \n",
       "7             0.896447           0.696375            0.877551   \n",
       "8             0.897203           0.729607            0.860922   \n",
       "9             0.872260           0.702417            0.868481   \n",
       "10            0.934996           0.649547            0.883598   \n",
       "11            0.779289           0.655589            0.716553   \n",
       "12            0.867725           0.708459            0.916100   \n",
       "13            0.897959           0.708459            0.841270   \n",
       "14            0.675737           0.679758            0.776266   \n",
       "15            0.704460           0.638973            0.795163   \n",
       "16            0.722600           0.611782            0.736206   \n",
       "17            0.718065           0.641994            0.705215   \n",
       "18            0.897203           0.725076            0.891912   \n",
       "19            0.723356           0.717523            0.924414   \n",
       "20            0.868481           0.658610            0.801965   \n",
       "21            0.836735           0.619335            0.635676   \n",
       "22            0.918367           0.654079            0.826909   \n",
       "23            0.787604           0.735650            0.873016   \n",
       "24            0.939531           0.734139            0.938020   \n",
       "25            0.914588           0.737160            0.949358   \n",
       "26            0.828420           0.705438            0.881330   \n",
       "27            0.937264           0.728097            0.942555   \n",
       "28            0.944822           0.712991            0.924414   \n",
       "29            0.846561           0.637462            0.733938   \n",
       "30            0.934996           0.722054            0.946334   \n",
       "31            0.942555           0.744713            0.948602   \n",
       "32            0.921391           0.690332            0.912320   \n",
       "33            0.934240           0.744713            0.941799   \n",
       "34            0.940287           0.720544            0.953137   \n",
       "35            0.925926           0.729607            0.948602   \n",
       "36            0.935752           0.734139            0.945578   \n",
       "37            0.935752           0.726586            0.947846   \n",
       "38            0.909297           0.703927            0.909297   \n",
       "39            0.942555           0.725076            0.940287   \n",
       "40            0.947090           0.731118            0.934996   \n",
       "41            0.768707           0.654079            0.803477   \n",
       "42            0.937264           0.746224            0.947846   \n",
       "43            0.951625           0.726586            0.937264   \n",
       "44            0.922902           0.735650            0.952381   \n",
       "45            0.940287           0.735650            0.948602   \n",
       "46            0.951625           0.743202            0.952381   \n",
       "47            0.919879           0.667674            0.876795   \n",
       "\n",
       "    split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.682300            0.864804      0.144459        0.003838   \n",
       "1            0.688351            0.891239      0.063238        0.008334   \n",
       "2            0.679274            0.837613      0.067283        0.005426   \n",
       "3            0.679274            0.886707      0.158460        0.007827   \n",
       "4            0.623298            0.728097      0.040626        0.016844   \n",
       "5            0.659607            0.703927      0.131727        0.015865   \n",
       "6            0.711044            0.917674      0.184444        0.006631   \n",
       "7            0.704992            0.886707      0.055997        0.009581   \n",
       "8            0.708018            0.882931      0.068562        0.004988   \n",
       "9            0.742814            0.922961      0.146532        0.008873   \n",
       "10           0.664145            0.833837      0.036340        0.014131   \n",
       "11           0.673222            0.781722      0.073570        0.014211   \n",
       "12           0.695915            0.909366      0.280576        0.007559   \n",
       "13           0.717095            0.893505      0.281599        0.014964   \n",
       "14           0.704992            0.851208      0.087334        0.005326   \n",
       "15           0.698941            0.910121      0.208802        0.008422   \n",
       "16           0.662632            0.845166      0.068322        0.015496   \n",
       "17           0.706505            0.817976      0.092937        0.008934   \n",
       "18           0.644478            0.740181      0.284525        0.014049   \n",
       "19           0.714070            0.926737      0.252996        0.014219   \n",
       "20           0.668684            0.799094      0.043577        0.006233   \n",
       "21           0.701967            0.890483      0.366120        0.011162   \n",
       "22           0.730711            0.893505      0.027666        0.011065   \n",
       "23           0.695915            0.820997      0.111496        0.020538   \n",
       "24           0.738275            0.938822      0.093119        0.009091   \n",
       "25           0.714070            0.940332      0.133912        0.021484   \n",
       "26           0.717095            0.924471      0.333705        0.011215   \n",
       "27           0.706505            0.935801      0.142636        0.009854   \n",
       "28           0.706505            0.933535      0.114926        0.013930   \n",
       "29           0.701967            0.808157      0.127889        0.011108   \n",
       "30           0.735250            0.948640      0.325970        0.007937   \n",
       "31           0.714070            0.939577      0.067300        0.015996   \n",
       "32           0.736762            0.942598      0.108048        0.014604   \n",
       "33           0.756430            0.950906      0.183907        0.014963   \n",
       "34           0.732224            0.944109      0.126460        0.003677   \n",
       "35           0.738275            0.932779      0.426031        0.020729   \n",
       "36           0.726172            0.947130      0.112370        0.006783   \n",
       "37           0.730711            0.945619      0.071954        0.011016   \n",
       "38           0.683812            0.870846      0.077983        0.013173   \n",
       "39           0.701967            0.937311      0.161299        0.019104   \n",
       "40           0.704992            0.939577      0.250601        0.006809   \n",
       "41           0.708018            0.898036      0.089953        0.025677   \n",
       "42           0.741301            0.949396      0.253217        0.007144   \n",
       "43           0.742814            0.946375      0.177979        0.005322   \n",
       "44           0.735250            0.949396      0.194354        0.022493   \n",
       "45           0.739788            0.946375      0.121901        0.009699   \n",
       "46           0.727685            0.960725      0.562426        0.020096   \n",
       "47           0.727685            0.947130      0.115709        0.012340   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.020697         0.026819  \n",
       "1         0.010563         0.014514  \n",
       "2         0.016384         0.022680  \n",
       "3         0.018822         0.022173  \n",
       "4         0.033223         0.072168  \n",
       "5         0.024678         0.033459  \n",
       "6         0.013390         0.007565  \n",
       "7         0.013878         0.007716  \n",
       "8         0.009838         0.014924  \n",
       "9         0.016663         0.024839  \n",
       "10        0.039037         0.041300  \n",
       "11        0.017351         0.030164  \n",
       "12        0.017263         0.021394  \n",
       "13        0.005619         0.025738  \n",
       "14        0.032543         0.071889  \n",
       "15        0.031499         0.084155  \n",
       "16        0.021491         0.054853  \n",
       "17        0.026334         0.050401  \n",
       "18        0.036644         0.072806  \n",
       "19        0.034113         0.095332  \n",
       "20        0.016659         0.032054  \n",
       "21        0.035758         0.109666  \n",
       "22        0.034876         0.038612  \n",
       "23        0.031464         0.035145  \n",
       "24        0.004352         0.000618  \n",
       "25        0.012898         0.014731  \n",
       "26        0.007901         0.039280  \n",
       "27        0.019320         0.002901  \n",
       "28        0.006376         0.008347  \n",
       "29        0.027044         0.046747  \n",
       "30        0.007654         0.005963  \n",
       "31        0.012851         0.003755  \n",
       "32        0.020412         0.012688  \n",
       "33        0.006973         0.006814  \n",
       "34        0.013769         0.005387  \n",
       "35        0.007868         0.009496  \n",
       "36        0.003454         0.005038  \n",
       "37        0.005693         0.005255  \n",
       "38        0.019383         0.018126  \n",
       "39        0.022475         0.002147  \n",
       "40        0.014291         0.004985  \n",
       "41        0.023842         0.054647  \n",
       "42        0.002320         0.005391  \n",
       "43        0.008569         0.005933  \n",
       "44        0.004894         0.013249  \n",
       "45        0.003706         0.003514  \n",
       "46        0.007588         0.004123  \n",
       "47        0.025752         0.028956  \n",
       "\n",
       "[48 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "CNN = KerasClassifier(build_fn=create_model, \n",
    "                epochs=1,\n",
    "                #max_len=x_train[1],\n",
    "                #batch_size=BATCH_SIZE,\n",
    "                verbose=0,\n",
    "                validation_split=0.1\n",
    "                )\n",
    "\n",
    "params_grid = dict(\n",
    "        filters = [[50],[100]],\n",
    "        kernel_size = [[30],[50]],\n",
    "        strides = [[5],[10],[50]],\n",
    "        dropout_rate = [[0.5]],\n",
    "        pool_size = [[10],[15]],\n",
    "        epochs = [50, 100]        \n",
    "        #batch_size = 100\n",
    ")                               \n",
    "\n",
    "grid_search = GridSearchCV(CNN, \n",
    "                           params_grid, \n",
    "                           scoring='accuracy', cv=3, \n",
    "                           return_train_score=True\n",
    "                           )\n",
    "\n",
    "#print('best params', grid_search.best_params_)\n",
    "\n",
    "\n",
    "print(\"Performing grid search...\")    \n",
    "t0 = time()\n",
    "\n",
    "#histories = []\n",
    "grid_results = grid_search.fit(x_train,y_train)\n",
    "\n",
    "print(\"done in %0.2fs and %0.1fmin\" % ((time() - t0), ((time() - t0) / 60) ))\n",
    "print()\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(params_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "display(pd.DataFrame(grid_search.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = best_parameters\n",
    "\n",
    "## create the model with the best params found\n",
    "model = create_model(filters=params['filters'],\n",
    "                     kernel_size=params['kernel_size'],\n",
    "                     strides=params['strides'],\n",
    "                     dropout_rate=params['dropout_rate'],\n",
    "                     pool_size=params['pool_size']\n",
    "                    )\n",
    "\n",
    "## Then train it and display the results\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=250,#params['epochs'],\n",
    "                    #batch_size=params['batch_size'],\n",
    "                    verbose = 0)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "directory='/home/rafael/'\n",
    "\n",
    "plot_history(history, directory=directory)\n",
    "\n",
    "full_multiclass_report(model,\n",
    "                       x_test,\n",
    "                       y_test,\n",
    "                       classes=classes_names,\n",
    "                       directory=directory\n",
    "                      )\n",
    "                       #batch_size=32,\n",
    "                       #binary= )\n",
    "        \n",
    "        \n",
    "#result = result\n",
    "# get_results(model, y_test, model.predict_classes(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 10,  1],\n",
       "       [21, 17,  1],\n",
       "       [ 5,  7, 10]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
