{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from functions.models import \n",
    "from Models.functions.datasets import getDatasets\n",
    "from Models.functions.metrics import evaluator\n",
    "from Models.functions.plot import ROC, plot_confusion_matrix\n",
    "from Models.functions.preprocessing import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 10000,\n",
       " 'clf__penalty': 'l1',\n",
       " 'vect__max_df': 0.8,\n",
       " 'vect__max_features': 3000}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'brmoral'\n",
    "task = 'polit'\n",
    "\n",
    "def getBestParams(task, dataset_name):\n",
    "    baseline = 'baseline1'\n",
    "    dataset_name = dataset_name.strip().lower()\n",
    "    task = task.strip().lower()\n",
    "    \n",
    "    # load excel params\n",
    "    baseline1 = pd.read_excel('../Reports/Reports.xlsx', baseline)\n",
    "    baseline1['Task'] = baseline1['Task'].str.lower()\n",
    "    baseline1['Name'] = baseline1['Name'].str.lower()\n",
    "    \n",
    "    best_params = baseline1[(baseline1['Name'] == dataset_name) & (baseline1['Task'] == task)]\n",
    "    \n",
    "    max_features = best_params['max features'].values[0]\n",
    "    \n",
    "    model_params = {\n",
    "                    'vect__max_features': max_features if max_features != 'None' and not pd.isna(max_features) else None,\n",
    "                    'vect__max_df': best_params['max df'].values[0] if not pd.isna(best_params['max df'].values[0]) else 1,\n",
    "                    'clf__C': best_params['C'].values[0] if not pd.isna(best_params['C'].values[0]) else 1000.0, \n",
    "                    'clf__penalty': best_params['P'].values[0] if not pd.isna(best_params['P'].values[0]) else 'l2'\n",
    "                    }\n",
    "    \n",
    "    return model_params\n",
    "\n",
    "getBestParams(task, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoder(y):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y)\n",
    "\n",
    "    return (le.transform(y), len(le.classes_), list(le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform classification for each problem / task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, y, n_classes, classes_name, params):\n",
    "    \n",
    "    # pipeline.set_params(**params)    \n",
    "    vect = TfidfVectorizer(max_features=params.get('vect__max_features'), max_df=params.get('vect__max_df'))\n",
    "    \n",
    "    K = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    t0 = time()\n",
    "    \n",
    "    predicted_y = []\n",
    "    expected_y = []    \n",
    "    score_y = []\n",
    "    \n",
    "    for train_index, test_index in K.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        X_train = vect.fit_transform(X_train)\n",
    "        X_test = vect.transform(X_test)\n",
    "        \n",
    "        clf = LogisticRegression(C=params.get('clf__C'), penalty=params.get('clf__penalty'), solver='liblinear')\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        predicted_y.extend(clf.predict(X_test))\n",
    "        expected_y.extend(y_test)\n",
    "        score_y.extend(clf.predict_proba(X_test))\n",
    "\n",
    "        ### get train score\n",
    "\n",
    "    # print(\"done in %0.2fs and %0.1fmin\" % ((time() - t0), ((time() - t0) / 60) ))\n",
    "    # print()\n",
    "    \n",
    "    report = pd.DataFrame(classification_report(expected_y, predicted_y, digits=5, target_names=classes_name, output_dict=True))\n",
    "    report = report.transpose()\n",
    "    \n",
    "    return (\n",
    "        report, \n",
    "        np.asarray(expected_y),\n",
    "        np.asarray(predicted_y),\n",
    "        np.asarray(score_y)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(task, dataset_name, output = None):    \n",
    "    datasets = getDatasets(task,'df', dataset_name)\n",
    "    for i in datasets.iterrows():\n",
    "\n",
    "        name = i[1]['dataset_name']\n",
    "        label = task\n",
    "        ds_path = i[1]['path']\n",
    "\n",
    "        # load training and test dataframes\n",
    "        training_path = ds_path + '/' + i[1]['training']        \n",
    "\n",
    "        df_training = pd.read_csv(training_path)#, usecols=cols)        \n",
    "        \n",
    "        df_training['text'] = df_training['text'].apply(clean)\n",
    "        \n",
    "        X_train = df_training['text'].values\n",
    "        y_train, n_classes, classes_name = labelEncoder(df_training[label].values)\n",
    "\n",
    "        # del(df_training)\n",
    "\n",
    "        # print(\"Dataset: {0} and task: {1}\".format(name, label))\n",
    "\n",
    "        # print(\"n_classes: {0}\".format(n_classes))\n",
    "\n",
    "        params = getBestParams(task, dataset_name)\n",
    "        if dataset_name == 'brmoral' and task == 'relig':        \n",
    "            params['clf__C'] = 1000\n",
    "        #params['clf__penalty'] = 'l1'\n",
    "        #params['clf__maxiter'] = '500'\n",
    "        print(\"params: \", params)\n",
    "\n",
    "        report, expected_y, predicted_y, score_y = model(X_train, y_train, n_classes, classes_name, params)\n",
    "\n",
    "        # get ROC\n",
    "        roc_c = ROC(expected_y, score_y, n_classes, task, dataset_name, classes_name)\n",
    "        report['roc'] = list(roc_c.values()) + [roc_c['macro']] * 2\n",
    "\n",
    "        # compute accuracy\n",
    "        accuracy = accuracy_score(expected_y, predicted_y)\n",
    "        report['accuracy'] = [accuracy] * (n_classes + 3)\n",
    "\n",
    "        # compute confusion matrix\n",
    "        c_matrix = confusion_matrix(expected_y, predicted_y)\n",
    "        plot_confusion_matrix(c_matrix, classes_name, task, dataset_name, True)\n",
    "        cm = pd.DataFrame(c_matrix, columns=classes_name, index=classes_name)\n",
    "\n",
    "        directory = './Reports/' + task + '/' + dataset_name + '/'\n",
    "        report.to_csv(directory + 'report.csv')\n",
    "        cm.to_csv(directory + 'confusion_matrix.csv')    \n",
    "\n",
    "        print(task, dataset_name, report)\n",
    "        print(cm)\n",
    "\n",
    "        # output.put('results for {0} and {1}'.format(task, dataset_name))\n",
    "        # output.put(report.to_dict())\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import random\n",
    "import string\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "# Define an output queue\n",
    "output = mp.Queue()\n",
    "\n",
    "task_list = ['relig','polit','education','professional','region','TI','gender','age']\n",
    "dataset_list = ['brmoral','b5post','esic','brblogset','enblogs','pan13_en','pan13_es']\n",
    "\n",
    "args = []\n",
    "for task in task_list:\n",
    "    for ds in dataset_list:\n",
    "        d = getDatasets(task,'df', ds)\n",
    "        if len(d.values) > 0:\n",
    "            args.append([task, ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Normalized confusion matrix\n",
      "[[0.53846154 0.37362637 0.08791209]\n",
      " [0.30434783 0.44565217 0.25      ]\n",
      " [0.24096386 0.31325301 0.44578313]]\n",
      "relig brmoral               f1-score  precision    recall  support  roc  accuracy\n",
      "r12           0.705570   0.545082  1.000000    133.0  0.5  0.545082\n",
      "r3            0.000000   0.000000  0.000000     90.0  0.5  0.545082\n",
      "r45           0.000000   0.000000  0.000000     21.0  0.5  0.545082\n",
      "micro avg     0.545082   0.545082  0.545082    244.0  0.5  0.545082\n",
      "macro avg     0.235190   0.181694  0.333333    244.0  0.5  0.545082\n",
      "weighted avg  0.384594   0.297114  0.545082    244.0  0.5  0.545082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age brmoral               f1-score  precision    recall  support       roc  accuracy\n",
      "a17-22        0.521277   0.505155  0.538462     91.0  0.706499  0.477444\n",
      "a25-29        0.424870   0.405941  0.445652     92.0  0.548913  0.477444\n",
      "a31-46        0.490066   0.544118  0.445783     83.0  0.710975  0.477444\n",
      "micro avg     0.477444   0.477444  0.477444    266.0  0.658402  0.477444\n",
      "macro avg     0.478738   0.485071  0.476632    266.0  0.658402  0.477444\n",
      "weighted avg  0.478195   0.482998  0.477444    266.0  0.658402  0.477444Normalized confusion matrix\n",
      "\n",
      "[[0.49193548 0.27419355 0.23387097]\n",
      " [0.32692308 0.40384615 0.26923077]\n",
      " [0.39175258 0.34020619 0.26804124]]\n",
      "Normalized confusion matrix\n",
      "[[0.47058824 0.52941176]\n",
      " [0.1407767  0.8592233 ]]Normalized confusion matrix\n",
      "\n",
      "[[0.34579439 0.65420561]\n",
      " [0.15137615 0.84862385]]\n",
      "education brmoral                                      f1-score  precision    recall  support  \\\n",
      "Básico + Superior incompleto         0.474708   0.458647  0.491935    124.0   \n",
      "Pós-graduação andamento ou completo  0.394366   0.385321  0.403846    104.0   \n",
      "Superior completo                    0.288889   0.313253  0.268041     97.0   \n",
      "micro avg                            0.396923   0.396923  0.396923    325.0   \n",
      "macro avg                            0.385988   0.385740  0.387941    325.0   \n",
      "weighted avg                         0.393539   0.391788  0.396923    325.0   \n",
      "\n",
      "                                          roc  accuracy  \n",
      "Básico + Superior incompleto         0.595851  0.396923  \n",
      "Pós-graduação andamento ou completo  0.562261  0.396923  \n",
      "Superior completo                    0.522608  0.396923  \n",
      "micro avg                            0.562489  0.396923  \n",
      "macro avg                            0.562489  0.396923  \n",
      "weighted avg                         0.562489  0.396923  \n",
      "gender brmoral               f1-score  precision    recall  support       roc  accuracy\n",
      "F             0.549020   0.658824  0.470588    119.0  0.249286  0.716923\n",
      "M             0.793722   0.737500  0.859223    206.0  0.750714  0.716923\n",
      "micro avg     0.716923   0.716923  0.716923    325.0  0.504722  0.716923\n",
      "macro avg     0.671371   0.698162  0.664906    325.0  0.504722  0.716923\n",
      "weighted avg  0.704123   0.708692  0.716923    325.0  0.504722  0.716923\n",
      "Normalized confusion matrix\n",
      "[[0.61607143 0.25       0.13392857]\n",
      " [0.23140496 0.54545455 0.2231405 ]\n",
      " [0.2173913  0.39130435 0.39130435]]\n",
      "TI brmoral               f1-score  precision    recall  support       roc  accuracy\n",
      "N             0.418079   0.528571  0.345794    107.0  0.330532  0.683077\n",
      "S             0.782241   0.725490  0.848624    218.0  0.669468  0.683077\n",
      "micro avg     0.683077   0.683077  0.683077    325.0  0.504941  0.683077\n",
      "macro avg     0.600160   0.627031  0.597209    325.0  0.504941  0.683077\n",
      "weighted avg  0.662348   0.660658  0.683077    325.0  0.504941  0.683077\n",
      "polit brmoral               f1-score  precision    recall  support       roc  accuracy\n",
      "p12           0.602620   0.589744  0.616071    112.0  0.755994  0.526154\n",
      "p3            0.525896   0.507692  0.545455    121.0  0.643615  0.526154\n",
      "p45           0.423529   0.461538  0.391304     92.0  0.680537  0.526154\n",
      "micro avg     0.526154   0.526154  0.526154    325.0  0.695656  0.526154\n",
      "macro avg     0.517349   0.519658  0.517610    325.0  0.695656  0.526154\n",
      "weighted avg  0.523359   0.522903  0.526154    325.0  0.695656  0.526154\n",
      "Normalized confusion matrix\n",
      "[[0.84571429 0.04571429 0.10857143]\n",
      " [0.75949367 0.02531646 0.21518987]\n",
      " [0.5        0.06122449 0.43877551]]\n",
      "relig b5post               f1-score  precision    recall  support       roc  accuracy\n",
      "r12           0.685185   0.575875  0.845714    175.0  0.685714  0.548295\n",
      "r3            0.042105   0.125000  0.025316     79.0  0.536097  0.548295\n",
      "r45           0.485876   0.544304  0.438776     98.0  0.701149  0.548295\n",
      "micro avg     0.548295   0.548295  0.548295    352.0  0.643292  0.548295\n",
      "macro avg     0.404389   0.415060  0.436602    352.0  0.643292  0.548295\n",
      "weighted avg  0.485368   0.465895  0.548295    352.0  0.643292  0.548295\n",
      "Normalized confusion matrix\n",
      "[[0.62913907 0.28476821 0.08609272]\n",
      " [0.25503356 0.57718121 0.16778523]\n",
      " [0.12389381 0.32743363 0.54867257]]\n",
      "age b5post               f1-score  precision    recall  support       roc  accuracy\n",
      "a18-20        0.637584   0.646259  0.629139    151.0  0.790228  0.588378\n",
      "a23-25        0.546032   0.518072  0.577181    149.0  0.691733  0.588378\n",
      "a28-61        0.582160   0.620000  0.548673    113.0  0.831652  0.588378\n",
      "micro avg     0.588378   0.588378  0.588378    413.0  0.773023  0.588378\n",
      "macro avg     0.588592   0.594777  0.584998    413.0  0.773023  0.588378\n",
      "weighted avg  0.589390   0.592828  0.588378    413.0  0.773023  0.588378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "Process Process-10:\n",
      "Process Process-12:\n",
      "Process Process-16:\n",
      "Process Process-15:\n",
      "Process Process-21:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-13:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-22:\n",
      "Process Process-17:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-14:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-6-b4ff2cee5612>\", line 28, in run\n",
      "    report, expected_y, predicted_y, score_y = model(X_train, y_train, n_classes, classes_name, params)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-b4ff2cee5612>\", line 28, in run\n",
      "    report, expected_y, predicted_y, score_y = model(X_train, y_train, n_classes, classes_name, params)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-4749a44d79b4>\", line 19, in model\n",
      "    X_train = vect.fit_transform(X_train)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-6-b4ff2cee5612>\", line 28, in run\n",
      "    report, expected_y, predicted_y, score_y = model(X_train, y_train, n_classes, classes_name, params)\n",
      "  File \"<ipython-input-6-b4ff2cee5612>\", line 14, in run\n",
      "    df_training['text'] = df_training['text'].apply(clean)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\", line 3194, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 1583, in fit_transform\n",
      "    X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-6-b4ff2cee5612>\", line 28, in run\n",
      "    report, expected_y, predicted_y, score_y = model(X_train, y_train, n_classes, classes_name, params)\n",
      "  File \"<ipython-input-5-4749a44d79b4>\", line 19, in model\n",
      "    X_train = vect.fit_transform(X_train)\n",
      "  File \"<ipython-input-5-4749a44d79b4>\", line 19, in model\n",
      "    X_train = vect.fit_transform(X_train)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"pandas/_libs/src/inference.pyx\", line 1472, in pandas._libs.lib.map_infer\n",
      "  File \"<ipython-input-5-4749a44d79b4>\", line 20, in model\n",
      "    X_test = vect.transform(X_test)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 1583, in fit_transform\n",
      "    X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n",
      "  File \"<ipython-input-6-b4ff2cee5612>\", line 14, in run\n",
      "    df_training['text'] = df_training['text'].apply(clean)\n",
      "  File \"<ipython-input-6-b4ff2cee5612>\", line 14, in run\n",
      "    df_training['text'] = df_training['text'].apply(clean)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 1583, in fit_transform\n",
      "    X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n",
      "  File \"/home/rafael/drive/Models/functions/preprocessing.py\", line 7, in clean\n",
      "    def clean(doc, lang = 'portuguese'):\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 1012, in fit_transform\n",
      "    self.fixed_vocabulary_)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 1611, in transform\n",
      "    X = super(TfidfVectorizer, self).transform(raw_documents)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\", line 3194, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"<ipython-input-6-b4ff2cee5612>\", line 14, in run\n",
      "    df_training['text'] = df_training['text'].apply(clean)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 922, in _count_vocab\n",
      "    for feature in analyze(doc):\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 1012, in fit_transform\n",
      "    self.fixed_vocabulary_)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 1012, in fit_transform\n",
      "    self.fixed_vocabulary_)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\", line 3194, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"<ipython-input-6-b4ff2cee5612>\", line 14, in run\n",
      "    df_training['text'] = df_training['text'].apply(clean)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 922, in _count_vocab\n",
      "    for feature in analyze(doc):\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 1066, in transform\n",
      "    _, X = self._count_vocab(raw_documents, fixed_vocab=True)\n",
      "  File \"pandas/_libs/src/inference.pyx\", line 1472, in pandas._libs.lib.map_infer\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\", line 3194, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 922, in _count_vocab\n",
      "    for feature in analyze(doc):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\", line 3194, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"/home/rafael/drive/Models/functions/preprocessing.py\", line 17, in clean\n",
      "    stop_words = set(stopwords.words(lang))\n",
      "  File \"pandas/_libs/src/inference.pyx\", line 1472, in pandas._libs.lib.map_infer\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 308, in <lambda>\n",
      "    tokenize(preprocess(self.decode(doc))), stop_words)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/nltk/corpus/reader/wordlist.py\", line 22, in words\n",
      "    return [line for line in line_tokenize(self.raw(fileids))\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 308, in <lambda>\n",
      "    tokenize(preprocess(self.decode(doc))), stop_words)\n",
      "  File \"pandas/_libs/src/inference.pyx\", line 1472, in pandas._libs.lib.map_infer\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 922, in _count_vocab\n",
      "    for feature in analyze(doc):\n",
      "  File \"pandas/_libs/src/inference.pyx\", line 1472, in pandas._libs.lib.map_infer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/rafael/drive/Models/functions/preprocessing.py\", line 7, in clean\n",
      "    def clean(doc, lang = 'portuguese'):\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/nltk/tokenize/simple.py\", line 138, in line_tokenize\n",
      "    return LineTokenizer(blanklines).tokenize(text)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 265, in <lambda>\n",
      "    return lambda doc: token_pattern.findall(doc)\n",
      "  File \"/home/rafael/drive/Models/functions/preprocessing.py\", line 17, in clean\n",
      "    stop_words = set(stopwords.words(lang))\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 265, in <lambda>\n",
      "    return lambda doc: token_pattern.findall(doc)\n",
      "  File \"/home/rafael/drive/Models/functions/preprocessing.py\", line 31, in clean\n",
      "    tokens = doc.split()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 308, in <lambda>\n",
      "    tokenize(preprocess(self.decode(doc))), stop_words)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/nltk/tokenize/simple.py\", line 110, in __init__\n",
      "    self._blanklines = blanklines\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/nltk/corpus/reader/wordlist.py\", line 22, in words\n",
      "    return [line for line in line_tokenize(self.raw(fileids))\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 265, in <lambda>\n",
      "    return lambda doc: token_pattern.findall(doc)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/nltk/corpus/reader/wordlist.py\", line 28, in raw\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/nltk/corpus/reader/wordlist.py\", line 28, in <listcomp>\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/nltk/data.py\", line 1132, in read\n",
      "    chars = self._read(size)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/nltk/data.py\", line 1396, in _read\n",
      "    new_bytes = self.stream.read()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4095b68ab644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Exit the completed processes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Get process results from the output queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-b4ff2cee5612>\", line 28, in run\n",
      "    report, expected_y, predicted_y, score_y = model(X_train, y_train, n_classes, classes_name, params)\n",
      "  File \"<ipython-input-5-4749a44d79b4>\", line 24, in model\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 1301, in fit\n",
      "    sample_weight=sample_weight)\n",
      "  File \"/home/rafael/.local/lib/python3.6/site-packages/sklearn/svm/base.py\", line 914, in _fit_liblinear\n",
      "    epsilon, sample_weight)\n",
      "KeyboardInterrupt\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Setup a list of processes that we want to run\n",
    "processes = [mp.Process(target=run, args=(x[0], x[1], output)) for x in args]\n",
    "\n",
    "# Run processes\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "# Exit the completed processes\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "# Get process results from the output queue\n",
    "results = [output.get() for p in processes]\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
